{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Available Models ---\n",
      "Available models (sorted by ELO):\n",
      "1. deepseek-ai/DeepSeek-R1 (ELO: 1618)\n",
      "2. chatgpt-4o-latest-2025-03-27 (ELO: 1484)\n",
      "3. deepseek-ai/DeepSeek-V3-0324 (ELO: 1477)\n",
      "4. gemini-2.5-pro-exp-03-25 (ELO: 1397)\n",
      "5. claude-3-5-sonnet-20241022 (ELO: 1369)\n",
      "6. chatgpt-4o-latest-2025-01-29 (ELO: 1364)\n",
      "7. RekaAI/reka-flash-3 (ELO: 1350)\n",
      "8. qwen/qwq-32b (ELO: 1344)\n",
      "9. claude-3-7-sonnet-20250219 (ELO: 1335)\n",
      "10. google/gemma-3-27b-it (ELO: 1249)\n",
      "11. gpt-4.5-preview (ELO: 1196)\n",
      "12. CohereForAI/c4ai-command-a-03-2025 (ELO: 1138)\n",
      "13. anthropic/claude-3.5-haiku-20241022 (ELO: 1125)\n",
      "14. google/gemma-3-12b-it (ELO: 1119)\n",
      "15. sam-paech/Darkest-muse-v1 (ELO: 1107)\n",
      "16. gemini-2.0-flash-001 (ELO: 1092)\n",
      "17. allura-org/Gemma-3-Glitter-12B (ELO: 1071)\n",
      "18. google/gemma-3-4b-it (ELO: 1039)\n",
      "19. ifable/gemma-2-Ifable-9B (ELO: 1006)\n",
      "20. ToastyPigeon/Gemma-3-Starshine-12B (ELO: 796)\n",
      "21. gpt-4o-mini (ELO: 796)\n",
      "22. google/gemma-2-9b-it (ELO: 796)\n",
      "23. mistralai/Mistral-Nemo-Instruct-2407 (ELO: 792)\n",
      "24. meta-llama/llama-3.1-405b-instruct (ELO: 785)\n",
      "25. liquid/lfm-7b (ELO: 689)\n",
      "26. mistralai/mistral-small-3.1-24b-instruct-2503 (ELO: 661)\n",
      "27. meta-llama/llama-3.1-70b-instruct (ELO: 640)\n",
      "28. meta-llama/llama-3.1-8b-instruct (ELO: 621)\n",
      "29. openai/gpt-4-0314 (ELO: 610)\n",
      "30. mistralai/Mistral-Small-24B-Instruct-2501 (ELO: 559)\n",
      "31. anthropic/claude-3-haiku (ELO: 553)\n",
      "32. meta-llama/llama-3.2-3b-instruct (ELO: 465)\n",
      "33. openai/gpt-3.5-turbo-0613 (ELO: 243)\n",
      "34. meta-llama/llama-3.2-1b-instruct (ELO: -17)\n",
      "------------------------\n",
      "\n",
      "Generating and saving HTML reports for all models...\n",
      "\n",
      "No models found in ELO data to generate reports for.\n",
      "\n",
      "Script finished.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import HTML, display\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "from core.metrics import calculate_repetition_metric, get_top_repetitive_words, get_multi_prompt_ngrams, calculate_slop_index_new\n",
    "\n",
    "# --- Add core directory to Python path ---\n",
    "SCRIPT_DIR = os.path.dirname(os.path.abspath('./')) # Assumes running from parent dir of script\n",
    "CORE_DIR = os.path.join(SCRIPT_DIR, 'core')\n",
    "if CORE_DIR not in sys.path:\n",
    "    sys.path.insert(0, CORE_DIR)\n",
    "\n",
    "MODELS_TO_IGNORE = [\n",
    "        'mistralai/ministral-3b',\n",
    "        'ministral-3b'\n",
    "    ]\n",
    "\n",
    "MODEL_NAME_SUBS = {\n",
    "    'deepseek/deepseek-r1': 'deepseek-ai/DeepSeek-R1',\n",
    "    'deepseek/deepseek-chat-v3-0324': 'deepseek-ai/DeepSeek-V3-0324',\n",
    "    'anthropic/claude-3.5-sonnet': 'claude-3-5-sonnet-20241022',\n",
    "    'openai/chatgpt-4o-latest': 'chatgpt-4o-latest-2025-01-29',\n",
    "    'anthropic/claude-3.7-sonnet': 'claude-3-7-sonnet-20250219',\n",
    "    'openai/gpt-4.5-preview': 'gpt-4.5-preview',\n",
    "    'cohere/command-a': 'CohereForAI/c4ai-command-a-03-2025',\n",
    "    'anthropic/claude-3.5-haiku': 'claude-3-5-haiku-20241022',\n",
    "    'google/gemini-2.0-flash-001': 'gemini-2.0-flash-001',\n",
    "    'openai/gpt-4o-mini': 'gpt-4o-mini',\n",
    "    'mistralai/mistral-nemo': 'mistralai/Mistral-Nemo-Instruct-2407',\n",
    "    'mistralai/mistral-small-3.1-24b-instruct': 'mistralai/Mistral-Small-3.1-24B-Instruct-2503',\n",
    "    'mistralai/mistral-small-24b-instruct-2501': 'mistralai/Mistral-Small-24B-Instruct-2501',\n",
    "    'mistralai/ministral-3b': 'ministral-3b',\n",
    "    'chatgpt-4o-latest': 'chatgpt-4o-latest-2025-03-27',\n",
    "    'rekaai/reka-flash-3:free': 'RekaAI/reka-flash-3',\n",
    "}\n",
    "\n",
    "# --- Helper function to update model name if a substitution exists ---\n",
    "def get_updated_model_name(original: str) -> str:\n",
    "    return MODEL_NAME_SUBS.get(original, original)\n",
    "\n",
    "# --- Import metrics functions ---\n",
    "try:\n",
    "    from core.metrics import calculate_slop_index, calculate_complexity_index\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing metrics from core.metrics: {e}\", file=sys.stderr)\n",
    "    print(\"Please ensure core/metrics.py exists and is in the Python path.\", file=sys.stderr)\n",
    "    # Define dummy functions if import fails to avoid crashing later\n",
    "    def calculate_slop_index(text: str) -> float: return -1.0\n",
    "    def calculate_complexity_index(text: str) -> float: return -1.0\n",
    "\n",
    "# Config variables\n",
    "RUNS_FILE = \"creative_bench_runs.json\"\n",
    "ELO_RESULTS_FILE = \"elo_results.json\"\n",
    "ELO_RESULTS_UPDATED_FILE = \"elo_results_with_metrics.json\"\n",
    "\n",
    "PROMPTS_ORDER = [\n",
    "    \"25\", \"9\", \"8\", \"33\", \"31\", \"4\", \"3\", \"32\", \"20\", \"30\",\n",
    "    \"15\", \"19\", \"18\", \"7\", \"28\", \"6\", \"5\", \"16\", \"1\", \"2\",\n",
    "    \"10\", \"11\", \"12\", \"13\", \"14\", \"17\", \"21\", \"22\", \"23\",\n",
    "    \"24\", \"26\", \"29\"\n",
    "]\n",
    "\n",
    "# --- Existing Functions (load_json_file, sanitize_model_name, etc.) ---\n",
    "def load_json_file(file_path: str) -> Dict:\n",
    "    \"\"\"Load data from a JSON file.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            return json.load(f)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding JSON from {file_path}\")\n",
    "            return {}\n",
    "\n",
    "def sanitize_model_name(model_name: str) -> str:\n",
    "    \"\"\"Sanitize model name for use in filenames.\"\"\"\n",
    "    sanitized = model_name.replace(\"/\", \"__\")\n",
    "    unsafe_chars = r'<>:\"|?*\\\\'\n",
    "    for char in unsafe_chars:\n",
    "        sanitized = sanitized.replace(char, '-')\n",
    "    return sanitized\n",
    "\n",
    "def generate_model_report(model_name: str, run_key: Optional[str] = None, save_to_file: bool = False) -> HTML:\n",
    "    \"\"\"\n",
    "    Generate an HTML report for a specific model with theme and font selection,\n",
    "    including a back button and dark mode toggle.\n",
    "\n",
    "    Args:\n",
    "        model_name: The name of the model to generate the report for\n",
    "        run_key: Optional specific run key to use\n",
    "        save_to_file: Whether to save the report to an HTML file\n",
    "\n",
    "    Returns:\n",
    "        An HTML object containing the report\n",
    "    \"\"\"\n",
    "    # --- Data Loading and Processing (Identical to previous version) ---\n",
    "    runs_data = load_json_file(RUNS_FILE)\n",
    "    elo_data = load_json_file(ELO_RESULTS_FILE)\n",
    "\n",
    "    if run_key is None:\n",
    "        matching_runs = [k for k, v in runs_data.items() if v.get(\"test_model\") == model_name]\n",
    "        if not matching_runs:\n",
    "            return HTML(f\"<h2>No runs found for model: {model_name}</h2>\")\n",
    "        run_key = matching_runs[-1]\n",
    "\n",
    "    if run_key not in runs_data:\n",
    "        return HTML(f\"<h2>Run key not found: {run_key}</h2>\")\n",
    "\n",
    "    run_data = runs_data[run_key]\n",
    "    original_model_name = run_data.get(\"test_model\", model_name)\n",
    "    display_model_name = get_updated_model_name(original_model_name) # Use updated name for display\n",
    "\n",
    "    creative_tasks = run_data.get(\"creative_tasks\", {})\n",
    "    if not creative_tasks:\n",
    "        return HTML(f\"<h2>No creative tasks found for run: {run_key}</h2>\")\n",
    "\n",
    "    # --- Data Processing (Identical) ---\n",
    "    creative_prompts = {}\n",
    "    try:\n",
    "        # Adjust path relative to SCRIPT_DIR if needed\n",
    "        creative_prompts_file = run_data.get(\"creative_prompts_file\", os.path.join(SCRIPT_DIR, \"data/creative_writing_prompts_v3.json\"))\n",
    "        if os.path.exists(creative_prompts_file):\n",
    "            creative_prompts = load_json_file(creative_prompts_file)\n",
    "        else:\n",
    "             print(f\"Warning: Creative prompts file not found at {creative_prompts_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not load creative prompts: {str(e)}\")\n",
    "\n",
    "    neg_criteria = []\n",
    "    try:\n",
    "        neg_criteria_file = 'data/negative_criteria.txt'\n",
    "        if os.path.exists(neg_criteria_file):\n",
    "            with open(neg_criteria_file, 'r') as f:\n",
    "                neg_criteria = [line.strip().lower() for line in list(f.readlines())]\n",
    "        else:\n",
    "            print(f\"Warning: {neg_criteria_file} not found. Negative criteria scoring adjustment will not be applied.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: {neg_criteria_file} not found. Negative criteria scoring adjustment will not be applied.\")\n",
    "\n",
    "    iterations = {}\n",
    "    for iter_idx, prompt_data in creative_tasks.items():\n",
    "        iter_score_sum = 0\n",
    "        iter_score_count = 0\n",
    "        for prompt_id, task_data in prompt_data.items():\n",
    "            if task_data.get(\"status\") not in [\"completed\", \"judged\"]: continue\n",
    "            results_by_mod = task_data.get(\"results_by_modifier\", {})\n",
    "            for seed_mod, block in results_by_mod.items():\n",
    "                j_scores = block.get(\"judge_scores\", {})\n",
    "                for metric, val in j_scores.items():\n",
    "                    if isinstance(val, (int, float)):\n",
    "                        iter_score_sum += (20 - val) if metric.lower() in neg_criteria else val\n",
    "                        iter_score_count += 1\n",
    "        iterations[iter_idx] = {\n",
    "            \"score\": round(iter_score_sum / iter_score_count, 2) if iter_score_count > 0 else 0,\n",
    "            \"prompts\": prompt_data\n",
    "        }\n",
    "    sorted_iterations = sorted(iterations.items(), key=lambda x: x[1][\"score\"], reverse=True)\n",
    "    # --- End Data Processing ---\n",
    "\n",
    "    # --- HTML Generation with Themes, Fonts, Back Button, Dark Mode ---\n",
    "    html_output = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <title>Model Outputs: {display_model_name}</title>\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "        <style>\n",
    "            /* ----------------------------------------------------\n",
    "            1) Font Imports & Face Definitions\n",
    "            ---------------------------------------------------- */\n",
    "            /* Lora (Used for Cozy Headers) */\n",
    "            @import url('https://fonts.googleapis.com/css2?family=Lora:ital,wght@0,400..700;1,400..700&display=swap');\n",
    "            /* Merriweather (Used for Modern Headers - fallback) */\n",
    "            @import url('https://fonts.googleapis.com/css2?family=Merriweather:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap');\n",
    "\n",
    "            /* Dynamic font loading will be handled with JavaScript */\n",
    "            /* We'll keep the font declarations in CSS for fallback purposes in case JS fails */\n",
    "\n",
    "            /* ----------------------------------------------------\n",
    "            2) Base Variables & Font Defaults\n",
    "            ---------------------------------------------------- */\n",
    "            :root {{\n",
    "                /* Default Theme: Cozy Light */\n",
    "                --theme-name: 'cozy'; /* JS uses this */\n",
    "\n",
    "                /* Fonts */\n",
    "                --font-body-cozy: 'Tiempos Text', Georgia, serif;\n",
    "                --font-heading-cozy: 'Lora', serif;\n",
    "                --font-body-modern: 'Inter', sans-serif; /* Changed modern default body */\n",
    "                --font-heading-modern: 'Besley', 'Merriweather', serif;\n",
    "                --font-ui: 'Lora', sans-serif; /* For controls */\n",
    "\n",
    "                /* Default to Cozy fonts */\n",
    "                --font-body: var(--font-body-cozy);\n",
    "                --font-heading: var(--font-heading-cozy);\n",
    "\n",
    "                /* Cozy Light Colors */\n",
    "                --bg-color: #fdfaf6;\n",
    "                --text-color: #3a3a3a;\n",
    "                --header-color: #5c4033;\n",
    "                --subheader-color: #7a6a60;\n",
    "                --border-color: #e0dcd1;\n",
    "                --accent-border-color: #d3c0a5;\n",
    "                --container-bg: #fffcf7;\n",
    "                --iter-header-bg: #f5f0e8;\n",
    "                --iter-header-hover-bg: #ede8de;\n",
    "                --prompt-header-bg: #faf5ef;\n",
    "                --prompt-header-hover-bg: #f5f0e8;\n",
    "                --judge-bg: #f3f6f9;\n",
    "                --judge-border: #c8d7e6;\n",
    "                --judge-text: #555;\n",
    "                --prompt-display-bg: #f9f6f0;\n",
    "                --toggle-icon-color: #8a7a70;\n",
    "                --shadow-color: rgba(0, 0, 0, 0.08);\n",
    "                --link-color: #7a6a60;\n",
    "                --link-hover-color: #5c4033;\n",
    "                --toggle-bg: #ccc; /* Not used visually now */\n",
    "                --toggle-checked-bg: #7a6a60; /* Not used visually now */\n",
    "                --toggle-knob-bg: white; /* Not used visually now */\n",
    "                --select-text-color: var(--subheader-color);\n",
    "                --select-chevron-color: var(--subheader-color);\n",
    "                --select-bg: transparent;\n",
    "                --select-border: none;\n",
    "            }}\n",
    "\n",
    "            /* ----------------------------------------------------\n",
    "            3) Cozy Dark Mode Variables\n",
    "            ---------------------------------------------------- */\n",
    "            body.theme-cozy.dark-mode {{\n",
    "                --bg-color: #2a2527;\n",
    "                --text-color: #fff9f2;\n",
    "                --header-color: #f7eee0;\n",
    "                --subheader-color: #e9dfd0;\n",
    "                --border-color: #3e3936;\n",
    "                --accent-border-color: #6a5349;\n",
    "                --container-bg: #312c2e;\n",
    "                --iter-header-bg: #342e2f;\n",
    "                --iter-header-hover-bg: #413935;\n",
    "                --prompt-header-bg: #312b2d;\n",
    "                --prompt-header-hover-bg: #3a3234;\n",
    "                --judge-bg: #2f3136;\n",
    "                --judge-border: #4e4944;\n",
    "                --judge-text: #fcf5eb;\n",
    "                --prompt-display-bg: #302a2c;\n",
    "                --toggle-icon-color: #c0b0a0;\n",
    "                --shadow-color: #0c0705;\n",
    "                --link-color: #d0bca8;\n",
    "                --link-hover-color: #ebdac5;\n",
    "                --toggle-bg: #524740; /* Not used visually now */\n",
    "                --toggle-checked-bg: #9a8778; /* Not used visually now */\n",
    "                --toggle-knob-bg: #ede6dc; /* Not used visually now */\n",
    "                --select-text-color: var(--subheader-color);\n",
    "                --select-chevron-color: var(--subheader-color);\n",
    "            }}\n",
    "\n",
    "            /* ----------------------------------------------------\n",
    "            4) Modern Theme Variables (Light & Dark)\n",
    "            ---------------------------------------------------- */\n",
    "            body.theme-modern {{\n",
    "                --theme-name: 'modern'; /* JS uses this */\n",
    "\n",
    "                /* Fonts */\n",
    "                --font-body: var(--font-body-modern);\n",
    "                --font-heading: var(--font-heading-modern);\n",
    "\n",
    "                /* Modern Light Colors */\n",
    "                --bg-color: #ffffff;\n",
    "                --text-color: #212529;\n",
    "                --header-color: #000000;\n",
    "                --subheader-color: #495057;\n",
    "                --border-color: #dee2e6;\n",
    "                --accent-border-color: #adb5bd;\n",
    "                --container-bg: #ffffff;\n",
    "                --iter-header-bg: #f8f9fa;\n",
    "                --iter-header-hover-bg: #e9ecef;\n",
    "                --prompt-header-bg: #ffffff;\n",
    "                --prompt-header-hover-bg: #f8f9fa;\n",
    "                --judge-bg: #f1f3f5;\n",
    "                --judge-border: #ced4da;\n",
    "                --judge-text: #343a40;\n",
    "                --prompt-display-bg: #f8f9fa;\n",
    "                --toggle-icon-color: #6c757d;\n",
    "                --shadow-color: rgba(0, 0, 0, 0.1);\n",
    "                --link-color: #007bff;\n",
    "                --link-hover-color: #0056b3;\n",
    "                --toggle-bg: #ced4da; /* Not used visually now */\n",
    "                --toggle-checked-bg: #007bff; /* Not used visually now */\n",
    "                --toggle-knob-bg: white; /* Not used visually now */\n",
    "                --select-text-color: var(--subheader-color);\n",
    "                --select-chevron-color: var(--subheader-color);\n",
    "            }}\n",
    "\n",
    "            body.theme-modern.dark-mode {{\n",
    "                /* Modern Dark Colors */\n",
    "                --bg-color: #1a1a1a;\n",
    "                --text-color: #e9ecef;\n",
    "                --header-color: #ffffff;\n",
    "                --subheader-color: #adb5bd;\n",
    "                --border-color: #495057;\n",
    "                --accent-border-color: #6c757d;\n",
    "                --container-bg: #212529;\n",
    "                --iter-header-bg: #343a40;\n",
    "                --iter-header-hover-bg: #495057;\n",
    "                --prompt-header-bg: #2c3034;\n",
    "                --prompt-header-hover-bg: #343a40;\n",
    "                --judge-bg: #343a40;\n",
    "                --judge-border: #495057;\n",
    "                --judge-text: #ced4da;\n",
    "                --prompt-display-bg: #343a40;\n",
    "                --toggle-icon-color: #adb5bd;\n",
    "                --shadow-color: rgba(0, 0, 0, 0.3);\n",
    "                --link-color: #69b1ff;\n",
    "                --link-hover-color: #a8d1ff;\n",
    "                --toggle-bg: #495057; /* Not used visually now */\n",
    "                --toggle-checked-bg: #0d6efd; /* Not used visually now */\n",
    "                --toggle-knob-bg: #dee2e6; /* Not used visually now */\n",
    "                --select-text-color: var(--subheader-color);\n",
    "                --select-chevron-color: var(--subheader-color);\n",
    "            }}\n",
    "\n",
    "\n",
    "            /* ----------------------------------------------------\n",
    "            5) Base Global Styles (Theme Independent)\n",
    "            ---------------------------------------------------- */\n",
    "            body {{\n",
    "                font-family: var(--font-body);\n",
    "                line-height: 1.7;\n",
    "                color: var(--text-color);\n",
    "                background-color: var(--bg-color);\n",
    "                max-width: 900px;\n",
    "                margin: 30px auto;\n",
    "                padding: 40px 50px;\n",
    "                border: 1px solid var(--border-color);\n",
    "                box-shadow: 0 5px 15px var(--shadow-color);\n",
    "                transition: background-color 0.3s, color 0.3s, border-color 0.3s;\n",
    "            }}\n",
    "            h1, h2, h3, h4 {{\n",
    "                font-family: var(--font-heading);\n",
    "                color: var(--header-color);\n",
    "                margin-top: 2em;\n",
    "                margin-bottom: 0.8em;\n",
    "                line-height: 1.3;\n",
    "                transition: color 0.3s;\n",
    "            }}\n",
    "            h1 {{\n",
    "                text-align: center;\n",
    "                font-size: 2.5em;\n",
    "                border-bottom: 2px solid var(--accent-border-color);\n",
    "                padding-bottom: 15px;\n",
    "                margin-bottom: 1.5em;\n",
    "                font-weight: 700;\n",
    "                transition: border-color 0.3s;\n",
    "                font-family: var(--font-ui) !important; /* Keep title in UI font */\n",
    "            }}\n",
    "            h2 {{\n",
    "                font-size: 1.8em;\n",
    "                font-weight: 700;\n",
    "            }}\n",
    "            h3 {{\n",
    "                font-size: 1.4em;\n",
    "                font-style: italic;\n",
    "                font-weight: 400;\n",
    "                color: var(--subheader-color);\n",
    "            }}\n",
    "            strong {{\n",
    "                font-weight: bold;\n",
    "                color: var(--header-color);\n",
    "                transition: color 0.3s;\n",
    "            }}\n",
    "            a {{\n",
    "                color: var(--link-color);\n",
    "                text-decoration: none;\n",
    "                transition: color 0.3s;\n",
    "            }}\n",
    "            a:hover {{\n",
    "                color: var(--link-hover-color);\n",
    "                text-decoration: underline;\n",
    "            }}\n",
    "            .top-controls {{\n",
    "                display: flex;\n",
    "                justify-content: space-between; /* Align items to opposite ends */\n",
    "                align-items: center;\n",
    "                margin-bottom: 20px;\n",
    "                padding-bottom: 10px;\n",
    "                border-bottom: 1px solid var(--border-color);\n",
    "                transition: border-color 0.3s;\n",
    "                font-family: var(--font-ui) !important; /* Keep controls in UI font */\n",
    "            }}\n",
    "            .back-button {{\n",
    "                font-family: var(--font-ui) !important;\n",
    "                font-size: 1em;\n",
    "                color: var(--select-text-color); /* Add this line to match other nav elements */\n",
    "                transition: color 0.3s; /* Add transition for smooth theme changes */\n",
    "            }}\n",
    "            \n",
    "            /* Controls right side container */\n",
    "            .controls-right {{\n",
    "                display: flex;\n",
    "                align-items: center;\n",
    "                gap: 15px; /* Space between controls */\n",
    "            }}\n",
    "\n",
    "            /* ----------------------------------------------------\n",
    "            6) Theme Specific Overrides & Effects\n",
    "            ---------------------------------------------------- */\n",
    "\n",
    "            /* Cozy Theme Specifics */\n",
    "            body.theme-cozy {{\n",
    "                /* Existing body styles are cozy defaults */\n",
    "            }}\n",
    "            body.theme-cozy.dark-mode {{\n",
    "                box-shadow: 0 5px 20px var(--shadow-color);\n",
    "                background-image: linear-gradient(to bottom, #211f21, #232022);\n",
    "            }}\n",
    "            body.theme-cozy.dark-mode .iteration-container {{\n",
    "                box-shadow: 0 2px 8px #000000;\n",
    "                border-color: var(--border-color);\n",
    "            }}\n",
    "            body.theme-cozy.dark-mode h1 {{\n",
    "                text-shadow: 0 1px 2px #000000;\n",
    "            }}\n",
    "            body.theme-cozy.dark-mode .content-block {{\n",
    "                border-color: var(--border-color);\n",
    "            }}\n",
    "            body.theme-cozy.dark-mode .prompt-text-display {{\n",
    "                border-left: 3px solid var(--accent-border-color);\n",
    "                background-color: #362e2b;\n",
    "            }}\n",
    "            body.theme-cozy.dark-mode .scores-container {{\n",
    "                color: #b0a598;\n",
    "            }}\n",
    "\n",
    "            /* Modern Theme Specifics */\n",
    "            body.theme-modern {{\n",
    "                padding: 35px 45px;\n",
    "            }}\n",
    "            body.theme-modern h1 {{\n",
    "                font-weight: 600;\n",
    "                border-bottom-width: 1px;\n",
    "            }}\n",
    "            body.theme-modern h2 {{\n",
    "                font-weight: 600;\n",
    "            }}\n",
    "            body.theme-modern h3 {{\n",
    "                font-weight: 500; /* Use Medium for Inter/Modern */\n",
    "                font-style: normal;\n",
    "            }}\n",
    "            body.theme-modern .iteration-header {{\n",
    "                font-weight: 600; /* Besley */\n",
    "            }}\n",
    "            body.theme-modern .prompt-header {{\n",
    "                font-weight: 500; /* Besley */\n",
    "                font-style: normal;\n",
    "            }}\n",
    "            body.theme-modern .prompt-text-display {{\n",
    "                border-left-width: 4px;\n",
    "                border-radius: 3px;\n",
    "                font-style: normal; /* Modern prompt less italic */\n",
    "            }}\n",
    "            body.theme-modern .judge-content {{\n",
    "                border-style: solid;\n",
    "                border-width: 1px;\n",
    "            }}\n",
    "            body.theme-modern strong {{\n",
    "                font-weight: 600; /* Use SemiBold for Inter/Modern */\n",
    "            }}\n",
    "\n",
    "\n",
    "            /* ----------------------------------------------------\n",
    "            7) Components / Containers (Theme Independent Styles)\n",
    "            ---------------------------------------------------- */\n",
    "\n",
    "            /* --- Selectors (Theme, Font) --- */\n",
    "            .control-select-wrapper {{\n",
    "                position: relative;\n",
    "                display: inline-block;\n",
    "            }}\n",
    "            .control-select {{\n",
    "                font-family: var(--font-ui) !important;\n",
    "                font-size: 0.9em;\n",
    "                color: var(--select-text-color);\n",
    "                background-color: var(--select-bg);\n",
    "                border: none;\n",
    "                padding: 2px 5px 2px 18px; /* top/bottom, right, left (space for chevron) */\n",
    "                margin: 0;\n",
    "                cursor: pointer;\n",
    "                appearance: none;\n",
    "                -webkit-appearance: none;\n",
    "                -moz-appearance: none;\n",
    "                transition: color 0.3s;\n",
    "                border-radius: 0; /* Ensure no default rounding */\n",
    "            }}\n",
    "            .control-select:focus {{\n",
    "                outline: none;\n",
    "            }}\n",
    "            /* Custom Chevron */\n",
    "            .control-select-wrapper::before {{ /* Changed from ::after */\n",
    "                content: '▼';\n",
    "                font-size: 0.6em;\n",
    "                color: var(--select-chevron-color);\n",
    "                position: absolute;\n",
    "                left: 5px; /* Position on the left */\n",
    "                top: 50%;\n",
    "                transform: translateY(-50%);\n",
    "                pointer-events: none;\n",
    "                transition: color 0.3s;\n",
    "            }}\n",
    "            .control-select option {{\n",
    "                background-color: var(--bg-color);\n",
    "                color: var(--text-color);\n",
    "                font-family: var(--font-ui); /* Ensure options use UI font */\n",
    "            }}\n",
    "\n",
    "            /* --- Dark Mode Toggle --- */\n",
    "            .mode-toggle {{\n",
    "                display: flex;\n",
    "                align-items: center;\n",
    "                font-family: var(--font-ui) !important;\n",
    "            }}\n",
    "            .mode-toggle .form-check-input {{ /* The hidden checkbox */\n",
    "                opacity: 0;\n",
    "                width: 0;\n",
    "                height: 0;\n",
    "                position: absolute;\n",
    "            }}\n",
    "            /* No visual switch span needed */\n",
    "            .mode-toggle .form-check-label {{ /* The clickable text */\n",
    "                font-family: var(--font-ui) !important;\n",
    "                font-size: 0.9em;\n",
    "                color: var(--subheader-color);\n",
    "                cursor: pointer;\n",
    "                transition: color 0.3s;\n",
    "                user-select: none; /* Prevent text selection on click */\n",
    "                padding: 2px 5px; /* Add some padding for easier clicking */\n",
    "            }}\n",
    "            .mode-toggle .form-check-label:hover {{\n",
    "                color: var(--link-hover-color); /* Use link hover color for feedback */\n",
    "            }}\n",
    "\n",
    "\n",
    "            /* --- Report Content Containers --- */\n",
    "            .iteration-container {{\n",
    "                margin: 30px 0;\n",
    "                border: 1px solid var(--border-color);\n",
    "                border-radius: 4px;\n",
    "                overflow: hidden;\n",
    "                background-color: var(--container-bg);\n",
    "                box-shadow: 0 2px 5px rgba(0,0,0,0.05);\n",
    "                transition: background-color 0.3s, border-color 0.3s, box-shadow 0.3s;\n",
    "            }}\n",
    "            .iteration-header {{\n",
    "                background: var(--iter-header-bg);\n",
    "                padding: 12px 20px;\n",
    "                cursor: pointer;\n",
    "                position: relative;\n",
    "                border-bottom: 1px solid var(--border-color);                \n",
    "                font-size: 1.2em;\n",
    "                font-weight: 700;\n",
    "                color: var(--header-color);\n",
    "                transition: background-color 0.3s, border-color 0.3s, color 0.3s;\n",
    "            }}\n",
    "            .iteration-header:hover {{\n",
    "                background: var(--iter-header-hover-bg);\n",
    "            }}\n",
    "            .prompt-container {{\n",
    "                border-top: 1px dashed var(--accent-border-color);\n",
    "                transition: border-color 0.3s;\n",
    "            }}\n",
    "            .prompt-container:first-child {{\n",
    "                border-top: none;\n",
    "            }}\n",
    "            .prompt-header {{\n",
    "                background: var(--prompt-header-bg);\n",
    "                padding: 10px 20px;\n",
    "                cursor: pointer;\n",
    "                font-size: 1.1em;\n",
    "                font-weight: 400;\n",
    "                color: var(--subheader-color);\n",
    "                transition: background-color 0.3s, color 0.3s;\n",
    "            }}\n",
    "            .prompt-header:hover {{\n",
    "                background: var(--prompt-header-hover-bg);\n",
    "            }}\n",
    "            .content-block {{\n",
    "                padding: 15px 25px;\n",
    "                border-top: 1px solid var(--border-color);\n",
    "                background-color: var(--container-bg);\n",
    "                transition: background-color 0.3s, border-color 0.3s;\n",
    "            }}\n",
    "            .response-content {{\n",
    "                white-space: pre-wrap;\n",
    "                font-family: var(--font-body);\n",
    "                font-size: 1.05em;\n",
    "                line-height: 1.7;\n",
    "                margin-bottom: 15px;\n",
    "                color: var(--text-color);\n",
    "                transition: color 0.3s;\n",
    "            }}\n",
    "            .judge-content {{\n",
    "                white-space: pre-wrap;\n",
    "                font-family: var(--font-body);\n",
    "                font-size: 1.0em;\n",
    "                line-height: 1.6;\n",
    "                background: var(--judge-bg);\n",
    "                border: 1px dashed var(--judge-border);\n",
    "                padding: 10px 15px;\n",
    "                margin-top: 10px;\n",
    "                border-radius: 3px;\n",
    "                color: var(--judge-text);\n",
    "                transition: background-color 0.3s, border-color 0.3s, color 0.3s;\n",
    "            }}\n",
    "            .prompt-text-display {{\n",
    "                font-style: italic; /* Default italic */\n",
    "                color: var(--subheader-color);\n",
    "                margin-bottom: 1em;\n",
    "                padding: 10px 15px;\n",
    "                background-color: var(--prompt-display-bg);\n",
    "                border-left: 3px solid var(--accent-border-color);\n",
    "                white-space: pre-wrap;\n",
    "                font-family: var(--font-body);\n",
    "                transition: background-color 0.3s, border-color 0.3s, color 0.3s, font-style 0.3s;\n",
    "            }}\n",
    "            .collapsible-content {{\n",
    "                display: none;\n",
    "                padding: 0;\n",
    "                background-color: var(--container-bg);\n",
    "                transition: background-color 0.3s;\n",
    "            }}\n",
    "            .expanded {{\n",
    "                display: block;\n",
    "            }}\n",
    "            .toggle-icon {{\n",
    "                display: inline-block;\n",
    "                width: 20px;\n",
    "                text-align: center;\n",
    "                font-weight: bold;\n",
    "                margin-right: 8px;\n",
    "                color: var(--toggle-icon-color);\n",
    "                transition: color 0.3s;\n",
    "            }}\n",
    "            .scores-container {{\n",
    "                margin-left: 20px;\n",
    "                font-style: italic;\n",
    "                color: #888;\n",
    "                font-size: 0.9em;\n",
    "            }}\n",
    "\n",
    "            /* Make certain elements always use the UI font */\n",
    "            h1, \n",
    "            .back-button,\n",
    "            .control-select,\n",
    "            .form-check-label,\n",
    "            .top-controls {{\n",
    "                font-family: var(--font-ui) !important; /* Override with UI font */\n",
    "            }}\n",
    "\n",
    "            h1.main-title, /* Add a class to the main title */\n",
    "            .back-button,\n",
    "            .control-select,\n",
    "            .form-check-label,\n",
    "            .top-controls {{\n",
    "                font-family: var(--font-ui) !important; /* Override with UI font */\n",
    "            }}\n",
    "\n",
    "            /* Allow iteration and prompt headers to use selected font */\n",
    "            .iteration-header,\n",
    "            .prompt-header {{\n",
    "                font-family: var(--font-body) !important;\n",
    "            }}\n",
    "\n",
    "            /* Mobile Responsiveness Adjustments */\n",
    "            @media screen and (max-width: 768px) {{\n",
    "    /* Body / Layout */\n",
    "    body.theme-cozy,\n",
    "    body.theme-modern {{\n",
    "        max-width: 100%;\n",
    "        margin: 10px 5px;\n",
    "        padding: 15px 10px;\n",
    "    }}\n",
    "\n",
    "    /* Headings */\n",
    "    body.theme-cozy h1,\n",
    "    body.theme-modern h1 {{\n",
    "        font-size: 1.8em;\n",
    "        padding-bottom: 10px;\n",
    "        margin-bottom: 1em;\n",
    "    }}\n",
    "\n",
    "    body.theme-cozy h2,\n",
    "    body.theme-modern h2 {{\n",
    "        font-size: 1.5em;\n",
    "    }}\n",
    "\n",
    "    body.theme-cozy h3,\n",
    "    body.theme-modern h3 {{\n",
    "        font-size: 1.2em;\n",
    "    }}\n",
    "\n",
    "    /* Iteration / Prompt headers */\n",
    "    body.theme-cozy .iteration-header,\n",
    "    body.theme-modern .iteration-header {{\n",
    "        padding: 10px 12px;\n",
    "    }}\n",
    "\n",
    "    body.theme-cozy .prompt-header,\n",
    "    body.theme-modern .prompt-header {{\n",
    "        padding: 8px 12px;\n",
    "    }}\n",
    "\n",
    "    /* Content blocks */\n",
    "    body.theme-cozy .content-block,\n",
    "    body.theme-modern .content-block {{\n",
    "        padding: 10px 12px;\n",
    "    }}\n",
    "\n",
    "    /* Top controls layout */\n",
    "    body.theme-cozy .top-controls,\n",
    "    body.theme-modern .top-controls {{\n",
    "        flex-direction: column;\n",
    "        align-items: flex-start;\n",
    "        gap: 10px;\n",
    "    }}\n",
    "\n",
    "    body.theme-cozy .controls-right,\n",
    "    body.theme-modern .controls-right {{\n",
    "        width: 100%;\n",
    "        justify-content: space-between;\n",
    "    }}\n",
    "}}\n",
    "\n",
    "\n",
    "\n",
    "        </style>\n",
    "    </head>\n",
    "    <body class=\"theme-cozy\">\n",
    "        <div class=\"top-controls\">\n",
    "            <div class=\"nav-left\">\n",
    "                <a href=\"javascript:history.back()\" class=\"back-button\">← Back</a>\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"controls-right\">\n",
    "                <div class=\"control-select-wrapper\">\n",
    "                    <select id=\"themeSelector\" class=\"control-select\" aria-label=\"Select Theme\">\n",
    "                        <option value=\"cozy\">Cozy</option>\n",
    "                        <option value=\"modern\">Modern</option>\n",
    "                    </select>\n",
    "                </div>\n",
    "\n",
    "                <div class=\"control-select-wrapper\">\n",
    "                    <select id=\"fontSelector\" class=\"control-select\" aria-label=\"Select Font\">\n",
    "                        <option value=\"tiempos\">Tiempos Text</option>\n",
    "                        <option value=\"bookerly\">Bookerly</option>\n",
    "                        <option value=\"bitter\">Bitter Pro</option>\n",
    "                        <option value=\"roboto\">Roboto</option>\n",
    "                        <option value=\"inter\">Inter</option>\n",
    "                        <option value=\"source_sans\">Source Sans 3</option>\n",
    "                        <option value=\"open_sans\">Open Sans</option>\n",
    "                        <option value=\"fira_sans\">Fira Sans</option>\n",
    "                        <option value=\"besley\">Besley</option>\n",
    "                    </select>\n",
    "                </div>\n",
    "\n",
    "                <div class=\"mode-toggle\">\n",
    "                    <input class=\"form-check-input\" type=\"checkbox\" id=\"darkModeToggle\">\n",
    "                    <label class=\"form-check-label\" for=\"darkModeToggle\" id=\"toggleLabel\">Light</label>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "\n",
    "        <h1 class=\"main-title\">Sample Outputs: {display_model_name}</h1>\n",
    "    \"\"\"\n",
    "\n",
    "    for display_idx, (iter_idx, iter_data) in enumerate(sorted_iterations):\n",
    "        is_first = display_idx == 0\n",
    "        html_output += f\"\"\"\n",
    "        <div class=\"iteration-container\">\n",
    "            <div class=\"iteration-header\" onclick=\"toggleContent('iteration-{iter_idx}')\">\n",
    "                <span class=\"toggle-icon\">{'−' if is_first else '+'}</span>\n",
    "                Iteration {display_idx + 1} — Avg Score: {round(iter_data['score']*5, 1)}\n",
    "            </div>\n",
    "            <div id=\"iteration-{iter_idx}\" class=\"collapsible-content {'expanded' if is_first else ''}\">\n",
    "        \"\"\"\n",
    "        prompt_data = iter_data[\"prompts\"]\n",
    "        prompt_items = []\n",
    "        for prompt_id, task_data in prompt_data.items():\n",
    "            if task_data.get(\"status\") not in [\"completed\", \"judged\"]: continue\n",
    "            prompt_text = task_data.get(\"base_prompt\", \"\")\n",
    "            if not prompt_text: continue\n",
    "\n",
    "            prompt_category = \"Unknown Category\"\n",
    "            prompt_title = f\"Prompt {prompt_id}\"\n",
    "            if prompt_id in creative_prompts:\n",
    "                prompt_info = creative_prompts[prompt_id]\n",
    "                prompt_category = prompt_info.get(\"category\", prompt_category)\n",
    "                prompt_title = prompt_info.get(\"title\", prompt_title)\n",
    "\n",
    "            all_responses = []\n",
    "            total_score = 0\n",
    "            score_count = 0\n",
    "            results_by_mod = task_data.get(\"results_by_modifier\", {})\n",
    "            for seed_mod, block in results_by_mod.items():\n",
    "                response_text = block.get(\"model_response\", \"\")\n",
    "                raw_judge_text = block.get(\"raw_judge_text\", \"\")\n",
    "                j_scores = block.get(\"judge_scores\", {})\n",
    "                response_scores_list = []\n",
    "                for metric, val in j_scores.items():\n",
    "                    if isinstance(val, (int, float)):\n",
    "                        score_val = (20 - val) if metric.lower() in neg_criteria else val\n",
    "                        total_score += score_val\n",
    "                        score_count += 1\n",
    "                        response_scores_list.append(f\"{metric}: {val}\")\n",
    "                all_responses.append({\n",
    "                    \"text\": response_text, \"judge_text\": raw_judge_text, \"scores\": \", \".join(response_scores_list)\n",
    "                })\n",
    "            avg_score = round(total_score / score_count, 2) if score_count > 0 else 0\n",
    "            prompt_items.append({\n",
    "                \"id\": prompt_id, \"prompt\": prompt_text, \"category\": prompt_category,\n",
    "                \"title\": prompt_title, \"responses\": all_responses, \"avg_score\": avg_score\n",
    "            })\n",
    "\n",
    "        def get_prompt_order(prompt_item):\n",
    "            try: return PROMPTS_ORDER.index(prompt_item[\"id\"])\n",
    "            except ValueError: return len(PROMPTS_ORDER)\n",
    "        prompt_items.sort(key=get_prompt_order)\n",
    "\n",
    "        for pidx, item in enumerate(prompt_items):\n",
    "            prompt_html_id = f\"prompt-{iter_idx}-{item['id']}\"\n",
    "            html_output += f\"\"\"\n",
    "            <div class=\"prompt-container\">\n",
    "                <div class=\"prompt-header\" onclick=\"toggleContent('{prompt_html_id}')\">\n",
    "                    <span class=\"toggle-icon\">+</span>\n",
    "                    {item['category'].capitalize()}: {item['title']} — Score: {round(item['avg_score']*5, 1)}\n",
    "                </div>\n",
    "                <div id=\"{prompt_html_id}\" class=\"collapsible-content\">\n",
    "                    <div class=\"content-block\">\n",
    "                        <div class=\"prompt-text-display\">\n",
    "<strong>Prompt:</strong><br>{item['prompt']}\n",
    "                        </div>\"\"\"\n",
    "            for ridx, response in enumerate(item[\"responses\"]):\n",
    "                html_output += f\"\"\"\n",
    "                        <div class=\"response-content\">\n",
    "<strong>Model Output:</strong><br>{response['text']}\n",
    "                        </div>\"\"\"\n",
    "                if response[\"judge_text\"]:\n",
    "                    scores_display = f\"<br><i>Scores: {response['scores']}</i>\" if response['scores'] else \"\"\n",
    "                    html_output += f\"\"\"\n",
    "                        <div class=\"judge-content\">\n",
    "<strong>Judge Evaluation:</strong><br>{response['judge_text']} {scores_display}\n",
    "                        </div>\"\"\"\n",
    "                if ridx < len(item[\"responses\"]) - 1:\n",
    "                    html_output += \"<hr style='border: none; border-top: 1px dotted var(--border-color); margin: 15px 0; transition: border-color 0.3s;'>\"\n",
    "            html_output += \"\"\"\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\"\"\"\n",
    "        html_output += \"\"\"\n",
    "            </div>\n",
    "        </div>\"\"\"\n",
    "    # --- End Iteration Loop ---\n",
    "\n",
    "    # --- JavaScript for Toggling, Dark Mode, Themes, Fonts with Dynamic Font Loading ---\n",
    "    html_output += \"\"\"\n",
    "        <script>\n",
    "            // --- DOM Elements ---\n",
    "            const body = document.body;\n",
    "            const themeSelector = document.getElementById('themeSelector');\n",
    "            const fontSelector = document.getElementById('fontSelector');\n",
    "            const darkModeToggle = document.getElementById('darkModeToggle');\n",
    "            const toggleLabel = document.getElementById('toggleLabel');\n",
    "\n",
    "            // --- Constants ---\n",
    "            const FONT_MAP = {\n",
    "                'tiempos': \"'Tiempos Text', Georgia, serif\",\n",
    "                'bookerly': \"'Bookerly', Georgia, serif\",\n",
    "                'bitter': \"'Bitter Pro', Georgia, serif\",\n",
    "                'roboto': \"'Roboto', sans-serif\",\n",
    "                'inter': \"'Inter', sans-serif\",\n",
    "                'source_sans': \"'Source Sans 3', sans-serif\",\n",
    "                'open_sans': \"'Open Sans', sans-serif\",\n",
    "                'fira_sans': \"'Fira Sans', sans-serif\",\n",
    "                'besley': \"'Besley', 'Merriweather', serif\"\n",
    "            };\n",
    "            \n",
    "            // Font definitions with URLs for dynamic loading\n",
    "            const FONT_DEFINITIONS = {\n",
    "                'tiempos': {\n",
    "                    family: 'Tiempos Text',\n",
    "                    variants: [\n",
    "                        { weight: 400, style: 'normal', url: 'fonts/tiempos_text/TiemposText-Regular.woff2' },\n",
    "                        { weight: 400, style: 'italic', url: 'fonts/tiempos_text/TiemposText-RegularItalic.woff2' },\n",
    "                        { weight: 700, style: 'normal', url: 'fonts/tiempos_text/TiemposText-Bold.woff2' }\n",
    "                    ],\n",
    "                    fallback: 'Georgia, serif'\n",
    "                },\n",
    "                'bookerly': {\n",
    "                    family: 'Bookerly',\n",
    "                    variants: [\n",
    "                        { weight: 400, style: 'normal', url: 'fonts/bookerly/Bookerly.woff' },\n",
    "                        { weight: 400, style: 'italic', url: 'fonts/bookerly/Bookerly Italic.woff' },\n",
    "                        { weight: 700, style: 'normal', url: 'fonts/bookerly/Bookerly Bold.woff' }\n",
    "                    ],\n",
    "                    fallback: 'Georgia, serif'\n",
    "                },\n",
    "                'bitter': {\n",
    "                    family: 'Bitter Pro',\n",
    "                    variants: [\n",
    "                        { weight: 400, style: 'normal', url: 'fonts/bitter_pro/BitterPro-Regular.ttf' },\n",
    "                        { weight: 400, style: 'italic', url: 'fonts/bitter_pro/BitterPro-Italic.ttf' },\n",
    "                        { weight: 700, style: 'normal', url: 'fonts/bitter_pro/BitterPro-Bold.ttf' }\n",
    "                    ],\n",
    "                    fallback: 'Georgia, serif'\n",
    "                },\n",
    "                'roboto': {\n",
    "                    family: 'Roboto',\n",
    "                    variants: [\n",
    "                        { weight: 400, style: 'normal', url: 'fonts/roboto/static/Roboto-Regular.ttf' },\n",
    "                        { weight: 400, style: 'italic', url: 'fonts/roboto/static/Roboto-Italic.ttf' },\n",
    "                        { weight: 700, style: 'normal', url: 'fonts/roboto/static/Roboto-Bold.ttf' }\n",
    "                    ],\n",
    "                    fallback: 'sans-serif'\n",
    "                },\n",
    "                'inter': {\n",
    "                    family: 'Inter',\n",
    "                    variants: [\n",
    "                        { weight: 400, style: 'normal', url: 'fonts/inter/static/Inter-Regular.ttf' },\n",
    "                        { weight: 400, style: 'italic', url: 'fonts/inter/static/Inter-Italic.ttf' },\n",
    "                        { weight: 700, style: 'normal', url: 'fonts/inter/static/Inter-Bold.ttf' }\n",
    "                    ],\n",
    "                    fallback: 'sans-serif'\n",
    "                },\n",
    "                'source_sans': {\n",
    "                    family: 'Source Sans 3',\n",
    "                    variants: [\n",
    "                        { weight: 400, style: 'normal', url: 'fonts/source_sans_3/static/SourceSans3-Regular.ttf' },\n",
    "                        { weight: 400, style: 'italic', url: 'fonts/source_sans_3/static/SourceSans3-Italic.ttf' },\n",
    "                        { weight: 700, style: 'normal', url: 'fonts/source_sans_3/static/SourceSans3-Bold.ttf' }\n",
    "                    ],\n",
    "                    fallback: 'sans-serif'\n",
    "                },\n",
    "                'open_sans': {\n",
    "                    family: 'Open Sans',\n",
    "                    variants: [\n",
    "                        { weight: 400, style: 'normal', url: 'fonts/open_sans/static/OpenSans-Regular.ttf' },\n",
    "                        { weight: 400, style: 'italic', url: 'fonts/open_sans/static/OpenSans-Italic.ttf' },\n",
    "                        { weight: 700, style: 'normal', url: 'fonts/open_sans/static/OpenSans-Bold.ttf' }\n",
    "                    ],\n",
    "                    fallback: 'sans-serif'\n",
    "                },\n",
    "                'fira_sans': {\n",
    "                    family: 'Fira Sans',\n",
    "                    variants: [\n",
    "                        { weight: 400, style: 'normal', url: 'fonts/fira_sans/FiraSans-Regular.ttf' },\n",
    "                        { weight: 400, style: 'italic', url: 'fonts/fira_sans/FiraSans-Italic.ttf' },\n",
    "                        { weight: 700, style: 'normal', url: 'fonts/fira_sans/FiraSans-Bold.ttf' }\n",
    "                    ],\n",
    "                    fallback: 'sans-serif'\n",
    "                },\n",
    "                'besley': {\n",
    "                    family: 'Besley',\n",
    "                    variants: [\n",
    "                        { weight: 400, style: 'normal', url: 'fonts/besley/Besley-VariableFont_wght.ttf' },\n",
    "                        { weight: 400, style: 'italic', url: 'fonts/besley/Besley-Italic-VariableFont_wght.ttf' }\n",
    "                    ],\n",
    "                    fallback: 'serif'\n",
    "                }\n",
    "            };\n",
    "            \n",
    "            // Define which fonts are generally sans-serif for logic purposes\n",
    "            const SANS_FONTS = ['roboto', 'inter', 'source_sans', 'open_sans', 'fira_sans'];\n",
    "\n",
    "            const THEME_DEFAULT_FONTS = {\n",
    "                'cozy': 'tiempos',\n",
    "                'modern': 'inter'\n",
    "            };\n",
    "            const THEME_DEFAULT_HEAD_FONTS = {\n",
    "                 'cozy': \"'Lora', serif\",\n",
    "                 'modern': \"'Besley', 'Merriweather', serif\"\n",
    "            };\n",
    "            \n",
    "            // Keep track of loaded fonts to avoid loading the same font multiple times\n",
    "            const loadedFonts = new Set();\n",
    "\n",
    "            // --- Dynamic Font Loading ---\n",
    "            async function loadFontFace(fontKey) {\n",
    "                if (loadedFonts.has(fontKey)) return; // Skip if already loaded\n",
    "                \n",
    "                const fontDef = FONT_DEFINITIONS[fontKey];\n",
    "                if (!fontDef) {\n",
    "                    console.warn(`Font definition not found for: ${fontKey}`);\n",
    "                    return;\n",
    "                }\n",
    "                \n",
    "                try {\n",
    "                    const fontLoadPromises = fontDef.variants.map(variant => {\n",
    "                        const fontFace = new FontFace(\n",
    "                            fontDef.family,\n",
    "                            `url(${variant.url})`,\n",
    "                            {\n",
    "                                weight: variant.weight,\n",
    "                                style: variant.style\n",
    "                            }\n",
    "                        );\n",
    "                        \n",
    "                        return fontFace.load().then(loadedFont => {\n",
    "                            document.fonts.add(loadedFont);\n",
    "                            return loadedFont;\n",
    "                        });\n",
    "                    });\n",
    "                    \n",
    "                    await Promise.all(fontLoadPromises);\n",
    "                    loadedFonts.add(fontKey);\n",
    "                    console.log(`Loaded font: ${fontDef.family}`);\n",
    "                } catch (err) {\n",
    "                    console.error(`Error loading font ${fontDef.family}:`, err);\n",
    "                    // Fall back silently - CSS will use fallback fonts\n",
    "                }\n",
    "            }\n",
    "\n",
    "            // --- Content Toggling ---\n",
    "            function toggleContent(id) {\n",
    "                const element = document.getElementById(id);\n",
    "                if (!element) return;\n",
    "                const isExpanded = element.classList.contains('expanded');\n",
    "                const header = element.previousElementSibling;\n",
    "                const toggleIcon = header ? header.querySelector('.toggle-icon') : null;\n",
    "\n",
    "                if (isExpanded) {\n",
    "                    element.classList.remove('expanded');\n",
    "                    if (toggleIcon) toggleIcon.textContent = '+';\n",
    "                } else {\n",
    "                    element.classList.add('expanded');\n",
    "                    if (toggleIcon) toggleIcon.textContent = '−';\n",
    "                }\n",
    "            }\n",
    "\n",
    "            // --- Shared settings with consistent keys ---\n",
    "            const STORAGE_PREFIX = 'model_viewer_';\n",
    "            const KEYS = {\n",
    "                THEME: `${STORAGE_PREFIX}theme`,\n",
    "                FONT: `${STORAGE_PREFIX}font`,\n",
    "                DARK_MODE: `modelViewerDarkModeEnabled`\n",
    "            };\n",
    "\n",
    "            // Save settings with consistent keys\n",
    "            function saveSettings(type, value) {\n",
    "                localStorage.setItem(KEYS[type], value);\n",
    "            }\n",
    "\n",
    "            // --- Dark Mode ---\n",
    "            function setDarkMode(isDark) {\n",
    "                body.classList.toggle('dark-mode', isDark);\n",
    "                toggleLabel.textContent = isDark ? 'Dark' : 'Light';\n",
    "                if (darkModeToggle.checked !== isDark) {\n",
    "                    darkModeToggle.checked = isDark;\n",
    "                }\n",
    "                saveSettings('DARK_MODE', isDark);\n",
    "            }\n",
    "\n",
    "\n",
    "            // --- Theme Selection ---\n",
    "            function applyTheme(themeName) {\n",
    "                body.classList.remove('theme-cozy', 'theme-modern');\n",
    "                body.classList.add(`theme-${themeName}`);\n",
    "                if (themeSelector.value !== themeName) {\n",
    "                    themeSelector.value = themeName;\n",
    "                }\n",
    "                saveSettings('THEME', themeName);\n",
    "                \n",
    "                // Re-apply font based on theme's default or user's saved preference\n",
    "                const savedFont = localStorage.getItem(KEYS.FONT);\n",
    "                const defaultFont = THEME_DEFAULT_FONTS[themeName] || 'tiempos';\n",
    "                applyFont(savedFont || defaultFont);\n",
    "            }\n",
    "\n",
    "            // --- Font Selection ---\n",
    "            async function applyFont(fontValue) {\n",
    "                // First, load the font faces dynamically\n",
    "                await loadFontFace(fontValue);\n",
    "                \n",
    "                const fontFamily = FONT_MAP[fontValue];\n",
    "                const currentTheme = localStorage.getItem(KEYS.THEME) || 'cozy';\n",
    "                let headingFontFamily = THEME_DEFAULT_HEAD_FONTS[currentTheme]; // Default heading for theme\n",
    "\n",
    "                if (fontFamily) {\n",
    "                    // Set body font - content text only, not UI elements\n",
    "                    body.style.setProperty('--font-body', fontFamily);\n",
    "\n",
    "                    // Determine appropriate heading font based on selected body font and theme\n",
    "                    if (currentTheme === 'modern') {\n",
    "                        headingFontFamily = THEME_DEFAULT_HEAD_FONTS['modern'];\n",
    "                    } else { \n",
    "                        headingFontFamily = THEME_DEFAULT_HEAD_FONTS['cozy'];\n",
    "                    }\n",
    "                    \n",
    "                    // Special case: If Besley is explicitly selected, use it for heading regardless of theme\n",
    "                    if (fontValue === 'besley') {\n",
    "                        headingFontFamily = FONT_MAP['besley'];\n",
    "                    }\n",
    "\n",
    "                    // Set the content heading font - not UI elements\n",
    "                    body.style.setProperty('--font-heading', headingFontFamily);\n",
    "\n",
    "                    // Update the selector value if needed\n",
    "                    if (fontSelector.value !== fontValue) {\n",
    "                        fontSelector.value = fontValue;\n",
    "                    }\n",
    "                    \n",
    "                    saveSettings('FONT', fontValue);\n",
    "                } else {\n",
    "                    console.warn(\"Font value not found in FONT_MAP:\", fontValue);\n",
    "                    // Fallback to theme default\n",
    "                    const theme = localStorage.getItem(KEYS.THEME) || 'cozy';\n",
    "                    applyFont(THEME_DEFAULT_FONTS[theme]);\n",
    "                }\n",
    "            }\n",
    "\n",
    "            // --- Event Listeners ---\n",
    "            darkModeToggle.addEventListener('change', function() {\n",
    "                setDarkMode(this.checked);\n",
    "            });\n",
    "\n",
    "            themeSelector.addEventListener('change', function() {\n",
    "                applyTheme(this.value);\n",
    "            });\n",
    "\n",
    "            fontSelector.addEventListener('change', function() {\n",
    "                applyFont(this.value);\n",
    "            });\n",
    "\n",
    "            // --- Initial Settings Application ---\n",
    "            async function applyInitialSettings() {\n",
    "                const savedDarkMode = localStorage.getItem(KEYS.DARK_MODE);\n",
    "                const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n",
    "                setDarkMode(savedDarkMode !== null ? (savedDarkMode === 'true') : prefersDark);\n",
    "\n",
    "                const savedTheme = localStorage.getItem(KEYS.THEME) || 'cozy';\n",
    "                applyTheme(savedTheme);\n",
    "\n",
    "                const savedFont = localStorage.getItem(KEYS.FONT) || THEME_DEFAULT_FONTS[savedTheme];\n",
    "                await applyFont(savedFont);\n",
    "                \n",
    "                fontSelector.value = savedFont || THEME_DEFAULT_FONTS[savedTheme];\n",
    "            }\n",
    "\n",
    "            applyInitialSettings();\n",
    "\n",
    "            // Optional: Listen for system theme changes ONLY if no preference is saved\n",
    "            window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', event => {\n",
    "                if (localStorage.getItem('darkModeEnabled') === null) {\n",
    "                    setDarkMode(event.matches);\n",
    "                }\n",
    "            });\n",
    "\n",
    "        </script>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    if save_to_file:\n",
    "        os.makedirs(\"results\", exist_ok=True)\n",
    "        sanitized_name = sanitize_model_name(get_updated_model_name(original_model_name))\n",
    "        filename = f\"results/{sanitized_name}.html\"\n",
    "        try:\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(html_output)\n",
    "            print(f\"Report saved to {filename}\")\n",
    "        except IOError as e:\n",
    "            print(f\"Error saving report to {filename}: {e}\")\n",
    "\n",
    "    return HTML(html_output)\n",
    "\n",
    "\n",
    "# --- Helper Functions (Identical to original) ---\n",
    "def view_model_report(model_name, run_key=None, save_to_file=False):\n",
    "    \"\"\"Display the HTML report for a given model and optionally save it.\"\"\"\n",
    "    report = generate_model_report(model_name, run_key, save_to_file)\n",
    "    display(report)\n",
    "\n",
    "def save_model_report(model_name, run_key=None):\n",
    "    \"\"\"Generate and save the HTML report for a given model.\"\"\"\n",
    "    generate_model_report(model_name, run_key, save_to_file=True)\n",
    "\n",
    "def list_available_models():\n",
    "    \"\"\"List all models available in the ELO results file.\"\"\"\n",
    "    elo_data = load_json_file(ELO_RESULTS_FILE)\n",
    "    if not elo_data:\n",
    "        print(\"No ELO data found.\")\n",
    "        return []\n",
    "    models = []\n",
    "    print(\"Available models (sorted by ELO):\")\n",
    "    for model_name, model_data in elo_data.items():\n",
    "        elo_score = model_data.get(\"elo\", -float('inf'))\n",
    "        models.append((model_name, elo_score))\n",
    "    models.sort(key=lambda x: x[1] if isinstance(x[1], (int, float)) else -float('inf'), reverse=True)\n",
    "    for rank, (name, elo) in enumerate(models, 1):\n",
    "        elo_display = f\"{elo:.0f}\" if isinstance(elo, (int, float)) else \"N/A\"\n",
    "        print(f\"{rank}. {get_updated_model_name(name)} (ELO: {elo_display})\") # Use updated name\n",
    "    return [name for name, _ in models]\n",
    "\n",
    "def list_model_runs(model_name):\n",
    "    \"\"\"List all runs available for a specific model.\"\"\"\n",
    "    runs_data = load_json_file(RUNS_FILE)\n",
    "    if not runs_data:\n",
    "        print(\"No runs data found.\")\n",
    "        return []\n",
    "    matching_runs = []\n",
    "    for key, data in runs_data.items():\n",
    "        if data.get(\"test_model\") == model_name:\n",
    "            start_time = data.get(\"start_time\", \"Unknown Time\")\n",
    "            status = data.get(\"status\", \"Unknown Status\")\n",
    "            matching_runs.append((key, start_time, status))\n",
    "    if not matching_runs:\n",
    "        print(f\"No runs found for model: {model_name}\")\n",
    "        return []\n",
    "    print(f\"\\nAvailable runs for {get_updated_model_name(model_name)}:\") # Use updated name\n",
    "    matching_runs.sort(key=lambda x: x[0])\n",
    "    for idx, (key, time, status) in enumerate(matching_runs, 1):\n",
    "        print(f\"{idx}. {key} (Started: {time}, Status: {status})\")\n",
    "    return [key for key, _, _ in matching_runs]\n",
    "\n",
    "\n",
    "import html # Import the html module for escaping\n",
    "\n",
    "# Assume MODELS_TO_IGNORE and get_updated_model_name are defined elsewhere\n",
    "\n",
    "def format_slop_profile_string(elo_data_with_metrics: Dict[str, Dict]) -> str:\n",
    "    \"\"\"\n",
    "    Formats repetitive word and n-gram data into a single multi-line string\n",
    "    with HTML formatting (items on single wrapping lines), delimited by model name,\n",
    "    suitable for embedding in JS. Frequency counts are included for n-grams only.\n",
    "\n",
    "    Args:\n",
    "        elo_data_with_metrics: The dictionary containing model data including\n",
    "                               'top_repetitive_words', 'top_multi_prompt_bigrams',\n",
    "                               and 'top_multi_prompt_trigrams'.\n",
    "\n",
    "    Returns:\n",
    "        A single multi-line string containing the formatted slop profiles for all models.\n",
    "    \"\"\"\n",
    "    output_string = \"\"\n",
    "\n",
    "    # Sort models consistently, e.g., by normalized ELO descending\n",
    "    sorted_models = sorted(\n",
    "        elo_data_with_metrics.items(),\n",
    "        key=lambda item: (\n",
    "            item[1].get(\"normalized_elo\", -float('inf'))\n",
    "            if isinstance(item[1].get(\"normalized_elo\"), (int, float))\n",
    "            else (\n",
    "                item[1].get(\"elo\", -float('inf'))\n",
    "                if isinstance(item[1].get(\"elo\"), (int, float))\n",
    "                else -float('inf')\n",
    "            )\n",
    "        ),\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    for model_name, data in sorted_models:\n",
    "        if model_name in MODELS_TO_IGNORE:\n",
    "            continue\n",
    "\n",
    "        updated_name = get_updated_model_name(model_name)\n",
    "        output_string += f\"##### {updated_name}\\n\"\n",
    "        \n",
    "        top_5 = data.get(\"top_5_similar\", [])\n",
    "        if top_5:\n",
    "            output_string += \"<h4>Most Similar To:</h4>\\n\"\n",
    "            output_string += \"<div class='slop-similar-section'>\\n\"\n",
    "            for item in top_5:\n",
    "                dist_str = f\"{item['distance']:.3f}\"\n",
    "                output_string += f\"<div class='slop-similar'>{html.escape(item['model'])} (distance={dist_str})</div>\\n\"\n",
    "            output_string += \"</div>\\n\"\n",
    "            output_string += \"\\n\"\n",
    "\n",
    "        # --- Top Repetitive Words ---\n",
    "        rep_words = data.get('top_repetitive_words', [])\n",
    "        output_string += \"<h4>Top Repetitive Words</h4>\\n\" # Keep heading simple\n",
    "        if rep_words:\n",
    "            output_string += \"<div class='slop-section-items'>\\n\" # Container for items\n",
    "            items_html = []\n",
    "            # Limit to top 50\n",
    "            for item in rep_words[:50]:\n",
    "                word = item.get('word', 'N/A')\n",
    "                safe_word = html.escape(word)\n",
    "                # No count for words\n",
    "                items_html.append(f\"<span class='slop-word-item'>{safe_word}</span>\")\n",
    "            output_string += \" \".join(items_html) # Join items with spaces\n",
    "            output_string += \"\\n</div>\\n\"\n",
    "        else:\n",
    "            output_string += \"<p><i>No multi-prompt repetitive words found.</i></p>\\n\"\n",
    "\n",
    "        # --- Top Multi-Prompt Bigrams ---\n",
    "        bigrams = data.get('top_multi_prompt_bigrams', [])\n",
    "        output_string += \"<h4>Top Bigrams</h4>\\n\" # Keep heading simple\n",
    "        if bigrams:\n",
    "            output_string += \"<div class='slop-section-items'>\\n\" # Container for items\n",
    "            items_html = []\n",
    "            # Limit to top 30\n",
    "            for item in bigrams[:30]:\n",
    "                ngram = item.get('ngram', 'N/A')\n",
    "                freq = item.get('frequency', 0) # Get frequency\n",
    "                safe_ngram = html.escape(ngram)\n",
    "                # Add frequency in parentheses\n",
    "                items_html.append(f\"<span class='slop-ngram-item'>{safe_ngram} ({freq})</span>\")\n",
    "            output_string += \" \".join(items_html) # Join items with spaces\n",
    "            output_string += \"\\n</div>\\n\"\n",
    "        else:\n",
    "            output_string += \"<p><i>No multi-prompt bigrams found.</i></p>\\n\"\n",
    "\n",
    "        # --- Top Multi-Prompt Trigrams ---\n",
    "        trigrams = data.get('top_multi_prompt_trigrams', [])\n",
    "        output_string += \"<h4>Top Trigrams</h4>\\n\" # Keep heading simple\n",
    "        if trigrams:\n",
    "            output_string += \"<div class='slop-section-items'>\\n\" # Container for items\n",
    "            items_html = []\n",
    "            # Limit to top 30\n",
    "            for item in trigrams[:30]:\n",
    "                ngram = item.get('ngram', 'N/A')\n",
    "                freq = item.get('frequency', 0) # Get frequency\n",
    "                safe_ngram = html.escape(ngram)\n",
    "                # Add frequency in parentheses\n",
    "                items_html.append(f\"<span class='slop-ngram-item'>{safe_ngram} ({freq})</span>\")\n",
    "            output_string += \" \".join(items_html) # Join items with spaces\n",
    "            output_string += \"\\n</div>\\n\"\n",
    "        else:\n",
    "            output_string += \"<p><i>No multi-prompt trigrams found.</i></p>\\n\"\n",
    "\n",
    "        output_string += \"\\n\" # Add a blank line between models in the string\n",
    "\n",
    "    return output_string.strip() # Remove leading/trailing whitespace\n",
    "\n",
    "\n",
    "# --- ADDED: import for distance computation\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# --- ADDED: compute top-5 nearest models (via combined Jaccard features)\n",
    "def calculate_combined_jaccard_similarities(elo_data_with_metrics: Dict[str, Dict], top_n: int = 1500):\n",
    "    \"\"\"\n",
    "    Builds a presence/absence matrix of \"combined\" features (top_repetitive_words,\n",
    "    bigrams, trigrams) for each model, computes pairwise Jaccard distances,\n",
    "    and stores each model’s top 5 neighbors under 'top_5_similar'.\n",
    "    \"\"\"\n",
    "    model_names = list(elo_data_with_metrics.keys())\n",
    "    model_to_features = {}\n",
    "\n",
    "    for m in model_names:\n",
    "        info = elo_data_with_metrics[m]\n",
    "        words = info.get(\"top_repetitive_words\", [])\n",
    "        bigrams = info.get(\"top_multi_prompt_bigrams\", [])\n",
    "        trigrams = info.get(\"top_multi_prompt_trigrams\", [])\n",
    "\n",
    "        w_count = top_n // 3\n",
    "        b_count = top_n // 3\n",
    "        t_count = top_n // 3\n",
    "\n",
    "        words_sorted = sorted(words, key=lambda x: x.get(\"score\", 0), reverse=True)[:w_count]\n",
    "        bigrams_sorted = sorted(bigrams, key=lambda x: x.get(\"frequency\", 0), reverse=True)[:b_count]\n",
    "        trigrams_sorted = sorted(trigrams, key=lambda x: x.get(\"frequency\", 0), reverse=True)[:t_count]\n",
    "\n",
    "        word_set = set(x[\"word\"] for x in words_sorted)\n",
    "        bigram_set = set(x[\"ngram\"] for x in bigrams_sorted)\n",
    "        trigram_set = set(x[\"ngram\"] for x in trigrams_sorted)\n",
    "\n",
    "        combined_set = word_set.union(bigram_set).union(trigram_set)\n",
    "        model_to_features[m] = combined_set\n",
    "\n",
    "    all_models = sorted(model_names)\n",
    "    global_vocab = set()\n",
    "    for feats in model_to_features.values():\n",
    "        global_vocab.update(feats)\n",
    "    if len(all_models) < 2 or not global_vocab:\n",
    "        return\n",
    "\n",
    "    global_vocab = sorted(global_vocab)\n",
    "    df = pd.DataFrame(0, index=all_models, columns=global_vocab, dtype=int)\n",
    "    for m in all_models:\n",
    "        for ft in model_to_features[m]:\n",
    "            if ft in df.columns:\n",
    "                df.loc[m, ft] = 1\n",
    "\n",
    "    dist_array = pdist(df.values, metric=\"jaccard\")\n",
    "    dist_matrix = squareform(dist_array)\n",
    "\n",
    "    for i, m in enumerate(all_models):\n",
    "        row_dist = dist_matrix[i, :]\n",
    "        pair_list = [(all_models[j], row_dist[j]) for j in range(len(all_models)) if j != i]\n",
    "        pair_list.sort(key=lambda x: x[1])  # ascending\n",
    "        top_5 = pair_list[:5]\n",
    "        elo_data_with_metrics[m][\"top_5_similar\"] = [\n",
    "            {\"model\": get_updated_model_name(t[0]), \"distance\": t[1]} for t in top_5\n",
    "        ]\n",
    "\n",
    "\n",
    "def calculate_and_print_metrics(save_updated_elo: bool = True, print_slop_profile: bool = True): # Added print_slop_profile flag\n",
    "    \"\"\"\n",
    "    Calculates aggregated metrics (length, vocab, slop, repetition) AND\n",
    "    extracts top multi-prompt N-grams for all models found in the runs file.\n",
    "    Repetition metrics & N-grams only consider words/sequences appearing in multiple prompts.\n",
    "    Merges metrics with ELO data, prints results, optionally saves the updated ELO data,\n",
    "    and optionally prints the formatted slop profile string.\n",
    "    \"\"\"\n",
    "    print(\"\\nCalculating aggregated metrics and N-grams...\")\n",
    "    runs_data = load_json_file(RUNS_FILE)\n",
    "    elo_data = load_json_file(ELO_RESULTS_FILE)\n",
    "\n",
    "    if not runs_data:\n",
    "        print(f\"Runs data file ('{RUNS_FILE}') is empty or not found. Cannot calculate metrics.\")\n",
    "        return\n",
    "\n",
    "    # Structure: { model_name: { prompt_id: [text1, text2, ...], ... }, ... }\n",
    "    model_texts_by_prompt = defaultdict(lambda: defaultdict(list))\n",
    "    print(\"Extracting text from runs (grouped by prompt)...\")\n",
    "    processed_runs = 0\n",
    "    # ... (rest of text extraction logic remains the same) ...\n",
    "    for run_key, run_data in runs_data.items():\n",
    "        model_name = run_data.get(\"test_model\")\n",
    "        if model_name in MODELS_TO_IGNORE:\n",
    "            continue\n",
    "        if not model_name: continue\n",
    "        creative_tasks = run_data.get(\"creative_tasks\", {})\n",
    "        if not creative_tasks: continue\n",
    "\n",
    "        run_has_text = False\n",
    "        for iter_idx, prompt_data in creative_tasks.items():\n",
    "            for prompt_id, task_data in prompt_data.items():\n",
    "                if task_data.get(\"status\") not in [\"completed\", \"judged\"]: continue\n",
    "                results_by_mod = task_data.get(\"results_by_modifier\", {})\n",
    "                for seed_mod, block in results_by_mod.items():\n",
    "                    response_text = block.get(\"model_response\")\n",
    "                    if isinstance(response_text, str) and response_text.strip():\n",
    "                        model_texts_by_prompt[model_name][prompt_id].append(response_text)\n",
    "                        run_has_text = True\n",
    "        if run_has_text: processed_runs += 1\n",
    "\n",
    "    print(f\"Extracted text for {len(model_texts_by_prompt)} models from {processed_runs} runs.\")\n",
    "    if not model_texts_by_prompt:\n",
    "        print(\"No model text found in any run. Cannot calculate metrics.\")\n",
    "        return\n",
    "\n",
    "    print(\"Calculating metrics and extracting N-grams per model...\")\n",
    "    model_metrics = {}\n",
    "    model_repetitive_words = {}\n",
    "    model_top_bigrams = {}\n",
    "    model_top_trigrams = {}\n",
    "\n",
    "    # --- Iterate through models ---\n",
    "    for model_name, prompts_data in model_texts_by_prompt.items():\n",
    "        all_responses_flat = [] # For slop, complexity, avg_length\n",
    "        texts_with_ids_list = [] # For repetition metrics\n",
    "        repetition_score = 0.0  # Default score\n",
    "        top_repetitive_words = [] # Default list\n",
    "        top_bigrams = []        # Default list\n",
    "        top_trigrams = []       # Default list\n",
    "\n",
    "        # Basic check: Does the model have *any* data?\n",
    "        if not prompts_data:\n",
    "            print(f\"Skipping {model_name}: No prompt data found.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n  Processing {model_name} (Responses from {len(prompts_data)} prompts)...\")\n",
    "\n",
    "        # Check for multi-prompt data BEFORE calculating repetition/n-grams\n",
    "        has_multi_prompt_data = len(prompts_data) >= 2\n",
    "\n",
    "        # Populate lists needed for different metrics\n",
    "        for prompt_id, texts in prompts_data.items():\n",
    "            all_responses_flat.extend(texts)\n",
    "            # Only add to list for repetition if multi-prompt data exists\n",
    "            if has_multi_prompt_data:\n",
    "                for text in texts:\n",
    "                    if isinstance(text, str) and text.strip(): # Ensure only valid text is added\n",
    "                        texts_with_ids_list.append((text, prompt_id))\n",
    "\n",
    "        # --- Calculate N-grams, etc. (only if multi-prompt data) ---\n",
    "        if has_multi_prompt_data and texts_with_ids_list:\n",
    "            ngram_calculation_error = False\n",
    "            word_extraction_error = False\n",
    "            \n",
    "            # Calculate total text length for normalization\n",
    "            total_text_length = sum(len(text.split()) for text, _ in texts_with_ids_list)\n",
    "            \n",
    "            print(\"      Calculating N-grams and N-gram Repetition Score (multi-prompt)...\")\n",
    "            try:\n",
    "                top_bigram_count = 0\n",
    "                top_trigram_count = 0\n",
    "                \n",
    "                top_bigrams = get_multi_prompt_ngrams(prompts_data, n=2, top_k=200, min_prompt_ids=2)\n",
    "                if top_bigrams:\n",
    "                    model_top_bigrams[model_name] = top_bigrams\n",
    "                    top_bigram_count = sum(freq for ngram, freq in top_bigrams[:40])\n",
    "                    print(f\"        Found {len(top_bigrams)} top bigrams meeting criteria.\")\n",
    "                else:\n",
    "                    print(\"        No bigrams met the multi-prompt criteria.\")\n",
    "\n",
    "                top_trigrams = get_multi_prompt_ngrams(prompts_data, n=3, top_k=200, min_prompt_ids=2)\n",
    "                if top_trigrams:\n",
    "                    model_top_trigrams[model_name] = top_trigrams\n",
    "                    top_trigram_count = sum(freq for ngram, freq in top_trigrams[:40])\n",
    "                    print(f\"        Found {len(top_trigrams)} top trigrams meeting criteria.\")\n",
    "                else:\n",
    "                    print(\"        No trigrams met the multi-prompt criteria.\")\n",
    "                    \n",
    "                # Calculate normalized repetition score\n",
    "                if total_text_length > 0:\n",
    "                    repetition_score = (top_bigram_count + top_trigram_count) / total_text_length * 1000\n",
    "                else:\n",
    "                    repetition_score = 0\n",
    "\n",
    "            except NameError:\n",
    "                print(\"      ERROR: `get_multi_prompt_ngrams` function not found. Skipping N-gram calculation and score.\")\n",
    "                ngram_calculation_error = True\n",
    "                repetition_score = 'Error'\n",
    "            except Exception as e:\n",
    "                print(f\"      ERROR calculating N-grams for {model_name}: {e}\")\n",
    "                ngram_calculation_error = True\n",
    "                repetition_score = 'Error'\n",
    "\n",
    "            if not ngram_calculation_error:\n",
    "                print(f\"        Calculated N-gram repetition score (normalized by text length * 1000): {repetition_score:.4f}\")\n",
    "\n",
    "            # --- Extract Top Repetitive Words ---\n",
    "            print(\"      Extracting top repetitive words (multi-prompt)...\")\n",
    "            try:\n",
    "                top_repetitive_words = get_top_repetitive_words(texts_with_ids_list, top_n=1000, min_prompt_ids=2) # Get more initially\n",
    "                if top_repetitive_words:\n",
    "                    model_repetitive_words[model_name] = top_repetitive_words # Store all found\n",
    "                    print(f\"        Found {len(top_repetitive_words)} repetitive words meeting criteria.\")\n",
    "                else:\n",
    "                    print(\"        No words met the multi-prompt repetitive word criteria.\")\n",
    "            except NameError:\n",
    "                print(\"      ERROR: `get_top_repetitive_words` function not found. Skipping word extraction.\")\n",
    "                word_extraction_error = True\n",
    "            except Exception as e:\n",
    "                print(f\"      ERROR extracting repetitive words for {model_name}: {e}\")\n",
    "                word_extraction_error = True\n",
    "\n",
    "        elif not has_multi_prompt_data:\n",
    "            print(f\"      Skipping N-grams, Repetition Score, and Repetitive Words: Only 1 prompt ID found.\")\n",
    "        elif not texts_with_ids_list:\n",
    "            print(\"      Skipping N-grams, Repetition Score, and Repetitive Words: No valid text entries found after filtering.\")\n",
    "\n",
    "        # --- Calculate Other Metrics ---\n",
    "        print(\"      Calculating other metrics (length, vocab, slop)...\")\n",
    "        num_responses = len(all_responses_flat)\n",
    "        if num_responses == 0:\n",
    "            print(f\"      Skipping length/vocab/slop metrics: No text after flattening.\")\n",
    "            avg_length = 0.0\n",
    "            vocab_complexity = 0.0\n",
    "            slop_score = 0.0\n",
    "        else:\n",
    "            total_chars = sum(len(r) for r in all_responses_flat if isinstance(r, str))\n",
    "            avg_length = round(total_chars / num_responses, 2)\n",
    "            all_text_combined = \"\\n\\n\".join(r for r in all_responses_flat if isinstance(r, str))\n",
    "            if not all_text_combined.strip():\n",
    "                 print(\"      Warning: Combined text is empty after joining, cannot calculate vocab/slop.\")\n",
    "                 vocab_complexity = 0.0\n",
    "                 slop_score = 0.0\n",
    "            else:\n",
    "                try:\n",
    "                    vocab_complexity = calculate_complexity_index(all_text_combined)\n",
    "                except Exception as e:\n",
    "                    print(f\"      ERROR calculating vocab complexity for {model_name}: {e}\")\n",
    "                    vocab_complexity = 'Error'\n",
    "                try:\n",
    "                    slop_score = calculate_slop_index_new(all_text_combined)\n",
    "                except Exception as e:\n",
    "                    print(f\"      ERROR calculating slop score for {model_name}: {e}\")\n",
    "                    slop_score = 'Error'\n",
    "\n",
    "        model_metrics[model_name] = {\n",
    "            'avg_length': avg_length,\n",
    "            'vocab_complexity': round(vocab_complexity, 4) if isinstance(vocab_complexity, (int, float)) and vocab_complexity != float('inf') else str(vocab_complexity),\n",
    "            'slop_score': round(slop_score, 4) if isinstance(slop_score, (int, float)) else str(slop_score),\n",
    "            'repetition_score': round(repetition_score, 4) if isinstance(repetition_score, (int, float)) else str(repetition_score) # Store potentially updated score\n",
    "        }\n",
    "\n",
    "        # --- Print Summary for Model ---\n",
    "        print(f\"    Metrics - Avg Len: {avg_length:.0f}, Vocab K: {model_metrics[model_name]['vocab_complexity']}, \"\n",
    "              f\"Slop: {model_metrics[model_name]['slop_score']}, Repetition (multi-prompt): {model_metrics[model_name]['repetition_score']}\")\n",
    "\n",
    "        if top_repetitive_words:\n",
    "            filtered_top_words = top_repetitive_words[:10] # Limit printout in console\n",
    "            print(f\"    Top multi-prompt repetitive words: \" + \", \".join([f\"{word} ({score:.1f}x)\" for word, score in filtered_top_words]))\n",
    "        elif has_multi_prompt_data:\n",
    "             print(\"    No words met the multi-prompt repetition criteria.\")\n",
    "\n",
    "        if top_bigrams:\n",
    "            print(\"    Top multi-prompt Bigrams:\")\n",
    "            for bg, freq in top_bigrams[:5]: # Limit printout\n",
    "                print(f\"      - {' '.join(bg)} ({freq})\")\n",
    "        elif has_multi_prompt_data:\n",
    "            print(\"    No bigrams met the multi-prompt criteria.\")\n",
    "\n",
    "        if top_trigrams:\n",
    "            print(\"    Top multi-prompt Trigrams:\")\n",
    "            for tg, freq in top_trigrams[:5]: # Limit printout\n",
    "                print(f\"      - {' '.join(tg)} ({freq})\")\n",
    "        elif has_multi_prompt_data:\n",
    "            print(\"    No trigrams met the multi-prompt criteria.\")\n",
    "\n",
    "\n",
    "    # --- Merging metrics with ELO data ---\n",
    "    print(\"\\nMerging metrics with ELO data...\")\n",
    "    updated_elo_data = elo_data.copy() if isinstance(elo_data, dict) else {}\n",
    "\n",
    "    # Add calculated metrics\n",
    "    for model_name, metrics in model_metrics.items():\n",
    "        if model_name not in updated_elo_data:\n",
    "            updated_elo_data[model_name] = {}\n",
    "            print(f\"  Note: Model '{model_name}' found in runs but not in ELO data. Added entry.\")\n",
    "        updated_elo_data[model_name].update(metrics)\n",
    "\n",
    "    # Add repetitive words if found\n",
    "    for model_name, words_list in model_repetitive_words.items():\n",
    "        if model_name in updated_elo_data:\n",
    "             updated_elo_data[model_name]['top_repetitive_words'] = [\n",
    "                 {\"word\": word, \"score\": float(score)}\n",
    "                 for word, score in words_list\n",
    "             ]\n",
    "\n",
    "    # Add N-grams if found\n",
    "    for model_name, ngrams_list in model_top_bigrams.items():\n",
    "         if model_name in updated_elo_data:\n",
    "             updated_elo_data[model_name]['top_multi_prompt_bigrams'] = [\n",
    "                 {\"ngram\": ' '.join(ngram), \"frequency\": int(freq)}\n",
    "                 for ngram, freq in ngrams_list\n",
    "             ]\n",
    "    for model_name, ngrams_list in model_top_trigrams.items():\n",
    "         if model_name in updated_elo_data:\n",
    "             updated_elo_data[model_name]['top_multi_prompt_trigrams'] = [\n",
    "                 {\"ngram\": ' '.join(ngram), \"frequency\": int(freq)}\n",
    "                 for ngram, freq in ngrams_list\n",
    "             ]\n",
    "\n",
    "    # --- Set default values for models present in ELO but potentially missing metrics ---\n",
    "    default_metrics = {\n",
    "        'avg_length': 0.0, 'vocab_complexity': 'N/A', 'slop_score': 'N/A',\n",
    "        'repetition_score': 0.0, 'top_repetitive_words': [],\n",
    "        'top_multi_prompt_bigrams': [], 'top_multi_prompt_trigrams': []\n",
    "    }\n",
    "    all_model_names = set(updated_elo_data.keys())\n",
    "    for model_name in all_model_names:\n",
    "        if model_name not in updated_elo_data: continue\n",
    "        for key, default_value in default_metrics.items():\n",
    "            updated_elo_data[model_name].setdefault(key, default_value)\n",
    "\n",
    "\n",
    "    # --- Normalize ELO scores ---\n",
    "    print(\"\\nNormalizing ELO scores...\")\n",
    "    raw_elo_scores = {}\n",
    "    for model_name, data in updated_elo_data.items():\n",
    "        elo = data.get('elo')\n",
    "        if isinstance(elo, (int, float)):\n",
    "            raw_elo_scores[model_name] = elo\n",
    "\n",
    "    anchor_models = {\n",
    "        'deepseek/deepseek-r1': 1500,\n",
    "        'meta-llama/llama-3.2-1b-instruct': 200\n",
    "    }\n",
    "\n",
    "    normalized_scores = normalize_elo_scores(raw_elo_scores, anchor_models)\n",
    "\n",
    "    normalized_count = 0\n",
    "    for model_name, normalized_elo in normalized_scores.items():\n",
    "        if model_name in updated_elo_data:\n",
    "            updated_elo_data[model_name]['normalized_elo'] = round(normalized_elo, 1)\n",
    "            normalized_count += 1\n",
    "\n",
    "    print(f\"  Normalized ELO scores for {normalized_count} models using anchor models.\")\n",
    "\n",
    "\n",
    "    # --- Print CSV Results ---\n",
    "    print(\"\\n--- Aggregated Metrics Results (CSV Format) ---\")\n",
    "    print(\"model_name,elo_score,creative_writing_score,avg_length,vocab_complexity,slop_score,repetition_score\")\n",
    "    sorted_models = sorted(\n",
    "        updated_elo_data.items(),\n",
    "        key=lambda item: (\n",
    "            item[1].get(\"normalized_elo\", -float('inf'))\n",
    "            if isinstance(item[1].get(\"normalized_elo\"), (int, float))\n",
    "            else (\n",
    "                item[1].get(\"elo\", -float('inf'))\n",
    "                if isinstance(item[1].get(\"elo\"), (int, float))\n",
    "                else -float('inf')\n",
    "            )\n",
    "        ),\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    for model_name, data in sorted_models:\n",
    "        if model_name in MODELS_TO_IGNORE:\n",
    "            continue\n",
    "        updated_name = get_updated_model_name(model_name)\n",
    "        elo = data.get('elo', 'N/A')\n",
    "        elo_display = f\"{elo:.1f}\" if isinstance(elo, (int, float)) else 'N/A'\n",
    "\n",
    "        norm_elo = data.get('normalized_elo', 'N/A')\n",
    "        norm_elo_display = f\"{norm_elo:.1f}\" if isinstance(norm_elo, (int, float)) else 'N/A'\n",
    "\n",
    "        creative_score = data.get('creative_writing_rubric_score_agg', 'N/A')\n",
    "        creative_score_display = f\"{creative_score:.2f}\" if isinstance(creative_score, (int, float)) else 'N/A'\n",
    "\n",
    "        avg_len = data.get('avg_length', 'N/A')\n",
    "        avg_len_display = f\"{avg_len:.0f}\" if isinstance(avg_len, (int, float)) else 'N/A'\n",
    "\n",
    "        vocab = data.get('vocab_complexity', 'N/A')\n",
    "        vocab_display = f\"{float(vocab):.2f}\" if isinstance(vocab, (int, float)) else str(vocab)\n",
    "\n",
    "        slop = data.get('slop_score', 'N/A')\n",
    "        slop_display = f\"{float(slop):.2f}\" if isinstance(slop, (int, float)) else str(slop)\n",
    "\n",
    "        repetition = data.get('repetition_score', 'N/A')\n",
    "        repetition_display = f\"{float(repetition):.2f}\" if isinstance(repetition, (int, float)) else str(repetition)\n",
    "\n",
    "        safe_model_name = f'\"{updated_name}\"' if ',' in updated_name else updated_name\n",
    "        print(f\"{safe_model_name},{norm_elo_display},{creative_score_display},{avg_len_display},{vocab_display},{slop_display},{repetition_display}\")\n",
    "\n",
    "\n",
    "    # --- ADDED: call our new combined Jaccard similarity function\n",
    "    calculate_combined_jaccard_similarities(updated_elo_data, top_n=1500)\n",
    "\n",
    "    # --- Save Updated ELO Data ---\n",
    "    if save_updated_elo:\n",
    "        print(f\"\\nSaving updated ELO data with metrics (and N-grams) to {ELO_RESULTS_UPDATED_FILE}...\")\n",
    "        try:\n",
    "            with open(ELO_RESULTS_UPDATED_FILE, 'w', encoding='utf-8') as f:\n",
    "                json.dump(updated_elo_data, f, indent=2, ensure_ascii=False)\n",
    "            print(\"Save successful.\")\n",
    "        except IOError as e:\n",
    "            print(f\"Error saving updated ELO data to {ELO_RESULTS_UPDATED_FILE}: {e}\")\n",
    "        except TypeError as e:\n",
    "             print(f\"Error serializing updated ELO data to JSON: {e}. Check for non-serializable types.\")\n",
    "\n",
    "\n",
    "    # --- Generate and Print Slop Profile String ---\n",
    "    if print_slop_profile:\n",
    "        print(\"\\n--- Generating Slop Profile String for JS ---\")\n",
    "        slop_profile_output = format_slop_profile_string(updated_elo_data)\n",
    "        print(\"\\n----- BEGIN SLOP PROFILE STRING -----\")\n",
    "        print(slop_profile_output)\n",
    "        print(\"----- END SLOP PROFILE STRING -----\\n\")\n",
    "\n",
    "\n",
    "def normalize_elo_scores(raw_scores, anchor_models=None):\n",
    "    \"\"\"\n",
    "    Normalize ELO scores by anchoring specific models to predefined values.\n",
    "    \n",
    "    Args:\n",
    "        raw_scores (dict): Dictionary of model names to raw ELO scores\n",
    "        anchor_models (dict, optional): Dictionary mapping model names to their anchor values.\n",
    "            Default: {'deepseek/deepseek-r1': 1500, 'mistralai/ministral-3b': 200}\n",
    "            \n",
    "    Returns:\n",
    "        dict: Dictionary of model names to normalized ELO scores\n",
    "    \"\"\"\n",
    "    if anchor_models is None:\n",
    "        anchor_models = {\n",
    "            'deepseek/deepseek-r1': 1500,\n",
    "            'meta-llama/llama-3.2-1b-instruct': 200\n",
    "        }\n",
    "    \n",
    "    # First check if we have at least two anchor models in our raw scores\n",
    "    valid_anchors = {k: v for k, v in anchor_models.items() if k in raw_scores}\n",
    "    \n",
    "    if len(valid_anchors) < 2:\n",
    "        print(f\"Warning: Not enough anchor models found in scores. \"\n",
    "              f\"Found {len(valid_anchors)} of {len(anchor_models)}. \"\n",
    "              f\"Returning raw scores.\")\n",
    "        return {k: v for k, v in raw_scores.items()}\n",
    "    \n",
    "    # Get first two valid anchors to calculate normalization\n",
    "    anchor_items = list(valid_anchors.items())\n",
    "    model_a, target_a = anchor_items[0]\n",
    "    model_b, target_b = anchor_items[1]\n",
    "    \n",
    "    raw_a = raw_scores[model_a]\n",
    "    raw_b = raw_scores[model_b]\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if raw_a == raw_b:\n",
    "        scale = 1.0\n",
    "    else:\n",
    "        scale = (target_a - target_b) / (raw_a - raw_b)\n",
    "    \n",
    "    shift = target_a - (scale * raw_a)\n",
    "    \n",
    "    # Apply the transformation to all scores\n",
    "    normalized_scores = {model: (score * scale + shift) for model, score in raw_scores.items()}\n",
    "    \n",
    "    return normalized_scores\n",
    "\n",
    "\n",
    "# --- Main Execution Block ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure the results directory exists for saving reports\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "    # 1. List available models (optional, uses updated names)\n",
    "    print(\"--- Available Models ---\")\n",
    "    models = list_available_models()\n",
    "    print(\"-\" * 24)\n",
    "\n",
    "    # 2. Calculate and print the aggregated metrics\n",
    "    #    Set save_updated_elo=True to save to ELO_RESULTS_UPDATED_FILE\n",
    "    #calculate_and_print_metrics(save_updated_elo=True) # Set to True to save the file\n",
    "    # print(\"-\" * 24)\n",
    "\n",
    "    # 3. Example: Generate and save reports for *all* models\n",
    "    #    (using the updated generate_model_report function)\n",
    "    \n",
    "    print(\"\\nGenerating and saving HTML reports for all models...\")\n",
    "    if models and False:\n",
    "        for model in models:\n",
    "            if model in MODELS_TO_IGNORE:\n",
    "                continue\n",
    "            print(f\"Processing report for: {get_updated_model_name(model)}\")\n",
    "            try:\n",
    "                save_model_report(model) # This now generates the report with themes/fonts\n",
    "            except Exception as e:\n",
    "                print(f\"  ERROR generating report for {model}: {e}\")\n",
    "        print(\"\\nFinished saving reports.\")\n",
    "    else:\n",
    "        print(\"\\nNo models found in ELO data to generate reports for.\")\n",
    "\n",
    "    # 4. Example: View a report directly in IPython/Jupyter (if available)\n",
    "    # if models and 'IPython' in sys.modules:\n",
    "    #     print(f\"\\nDisplaying report for {get_updated_model_name(models[0])} in IPython...\")\n",
    "    #     view_model_report(models[0]) # Display the first model's report\n",
    "    # else:\n",
    "    #      print(\"\\nSkipping direct display (not in IPython or no models found).\")\n",
    "\n",
    "    print(\"\\nScript finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-sam'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved C tree with highlight on 'ToastyPigeon/Gemma-3-Starshine-12B' => results/charts/ToastyPigeon__Gemma-3-Starshine-12B__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'ToastyPigeon/Gemma-3-Starshine-12B' => results/charts/ToastyPigeon__Gemma-3-Starshine-12B__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'allura-org/Gemma-3-Glitter-12B' => results/charts/allura-org__Gemma-3-Glitter-12B__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'allura-org/Gemma-3-Glitter-12B' => results/charts/allura-org__Gemma-3-Glitter-12B__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'anthropic/claude-3-haiku' => results/charts/anthropic__claude-3-haiku__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'anthropic/claude-3-haiku' => results/charts/anthropic__claude-3-haiku__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'anthropic/claude-3.5-haiku-20241022' => results/charts/anthropic__claude-3.5-haiku-20241022__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'anthropic/claude-3.5-haiku-20241022' => results/charts/anthropic__claude-3.5-haiku-20241022__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'anthropic/claude-3.5-sonnet' => results/charts/claude-3-5-sonnet-20241022__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'anthropic/claude-3.5-sonnet' => results/charts/claude-3-5-sonnet-20241022__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'anthropic/claude-3.7-sonnet' => results/charts/claude-3-7-sonnet-20250219__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'anthropic/claude-3.7-sonnet' => results/charts/claude-3-7-sonnet-20250219__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'chatgpt-4o-latest' => results/charts/chatgpt-4o-latest-2025-03-27__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'chatgpt-4o-latest' => results/charts/chatgpt-4o-latest-2025-03-27__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'cohere/command-a' => results/charts/CohereForAI__c4ai-command-a-03-2025__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'cohere/command-a' => results/charts/CohereForAI__c4ai-command-a-03-2025__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'deepseek/deepseek-chat-v3-0324' => results/charts/deepseek-ai__DeepSeek-V3-0324__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'deepseek/deepseek-chat-v3-0324' => results/charts/deepseek-ai__DeepSeek-V3-0324__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'deepseek/deepseek-r1' => results/charts/deepseek-ai__DeepSeek-R1__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'deepseek/deepseek-r1' => results/charts/deepseek-ai__DeepSeek-R1__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'gemini-2.5-pro-exp-03-25' => results/charts/gemini-2.5-pro-exp-03-25__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'gemini-2.5-pro-exp-03-25' => results/charts/gemini-2.5-pro-exp-03-25__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'google/gemini-2.0-flash-001' => results/charts/gemini-2.0-flash-001__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'google/gemini-2.0-flash-001' => results/charts/gemini-2.0-flash-001__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'google/gemma-2-9b-it' => results/charts/google__gemma-2-9b-it__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'google/gemma-2-9b-it' => results/charts/google__gemma-2-9b-it__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'google/gemma-3-12b-it' => results/charts/google__gemma-3-12b-it__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'google/gemma-3-12b-it' => results/charts/google__gemma-3-12b-it__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'google/gemma-3-27b-it' => results/charts/google__gemma-3-27b-it__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'google/gemma-3-27b-it' => results/charts/google__gemma-3-27b-it__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'google/gemma-3-4b-it' => results/charts/google__gemma-3-4b-it__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'google/gemma-3-4b-it' => results/charts/google__gemma-3-4b-it__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'google/gemma-3-4b-it:free' => results/charts/google__gemma-3-4b-it-free__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'google/gemma-3-4b-it:free' => results/charts/google__gemma-3-4b-it-free__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'ifable/gemma-2-Ifable-9B' => results/charts/ifable__gemma-2-Ifable-9B__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'ifable/gemma-2-Ifable-9B' => results/charts/ifable__gemma-2-Ifable-9B__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'liquid/lfm-7b' => results/charts/liquid__lfm-7b__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'liquid/lfm-7b' => results/charts/liquid__lfm-7b__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'meta-llama/llama-3.1-405b-instruct' => results/charts/meta-llama__llama-3.1-405b-instruct__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'meta-llama/llama-3.1-405b-instruct' => results/charts/meta-llama__llama-3.1-405b-instruct__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'meta-llama/llama-3.1-70b-instruct' => results/charts/meta-llama__llama-3.1-70b-instruct__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'meta-llama/llama-3.1-70b-instruct' => results/charts/meta-llama__llama-3.1-70b-instruct__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'meta-llama/llama-3.1-8b-instruct' => results/charts/meta-llama__llama-3.1-8b-instruct__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'meta-llama/llama-3.1-8b-instruct' => results/charts/meta-llama__llama-3.1-8b-instruct__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'meta-llama/llama-3.2-1b-instruct' => results/charts/meta-llama__llama-3.2-1b-instruct__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'meta-llama/llama-3.2-1b-instruct' => results/charts/meta-llama__llama-3.2-1b-instruct__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'meta-llama/llama-3.2-3b-instruct' => results/charts/meta-llama__llama-3.2-3b-instruct__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'meta-llama/llama-3.2-3b-instruct' => results/charts/meta-llama__llama-3.2-3b-instruct__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'mistralai/mistral-nemo' => results/charts/mistralai__Mistral-Nemo-Instruct-2407__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'mistralai/mistral-nemo' => results/charts/mistralai__Mistral-Nemo-Instruct-2407__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'mistralai/mistral-small-24b-instruct-2501' => results/charts/mistralai__Mistral-Small-24B-Instruct-2501__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'mistralai/mistral-small-24b-instruct-2501' => results/charts/mistralai__Mistral-Small-24B-Instruct-2501__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'mistralai/mistral-small-3.1-24b-instruct-2503' => results/charts/mistralai__mistral-small-3.1-24b-instruct-2503__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'mistralai/mistral-small-3.1-24b-instruct-2503' => results/charts/mistralai__mistral-small-3.1-24b-instruct-2503__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'openai/chatgpt-4o-latest' => results/charts/chatgpt-4o-latest-2025-01-29__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'openai/chatgpt-4o-latest' => results/charts/chatgpt-4o-latest-2025-01-29__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'openai/gpt-3.5-turbo-0613' => results/charts/openai__gpt-3.5-turbo-0613__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'openai/gpt-3.5-turbo-0613' => results/charts/openai__gpt-3.5-turbo-0613__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'openai/gpt-4-0314' => results/charts/openai__gpt-4-0314__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'openai/gpt-4-0314' => results/charts/openai__gpt-4-0314__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'openai/gpt-4.5-preview' => results/charts/gpt-4.5-preview__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'openai/gpt-4.5-preview' => results/charts/gpt-4.5-preview__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'openai/gpt-4o-mini' => results/charts/gpt-4o-mini__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'openai/gpt-4o-mini' => results/charts/gpt-4o-mini__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'qwen/qwq-32b' => results/charts/qwen__qwq-32b__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'qwen/qwq-32b' => results/charts/qwen__qwq-32b__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'rekaai/reka-flash-3:free' => results/charts/RekaAI__reka-flash-3__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'rekaai/reka-flash-3:free' => results/charts/RekaAI__reka-flash-3__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'sam-paech/Darkest-muse-v1' => results/charts/sam-paech__Darkest-muse-v1__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'sam-paech/Darkest-muse-v1' => results/charts/sam-paech__Darkest-muse-v1__phylo_tree_combined_rectangular.png\n",
      "Saved C tree with highlight on 'unsloth/gemma-3-12b-it' => results/charts/unsloth__gemma-3-12b-it__phylo_tree_combined_circular.png\n",
      "Saved R tree with highlight on 'unsloth/gemma-3-12b-it' => results/charts/unsloth__gemma-3-12b-it__phylo_tree_combined_rectangular.png\n",
      "\n",
      "Done. Generated circular & rectangular phylo trees for 36 models in 'results/charts'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Force Qt to run in 'offscreen' mode so ETE won't crash in headless environments\n",
    "os.environ[\"QT_QPA_PLATFORM\"] = \"offscreen\"\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import linkage, to_tree\n",
    "from ete3 import Tree, TreeStyle, NodeStyle, TextFace, faces\n",
    "\n",
    "##############################################################################\n",
    "# 1) Family assignments\n",
    "##############################################################################\n",
    "# Note: You said “gemma & gemini are both google.” So any model name \n",
    "# containing \"gemma\" or \"gemini\" is also mapped to Google in this dict.\n",
    "\n",
    "model_to_family = {\n",
    "    'google/gemini-2.0-flash-001': 'Google',\n",
    "    'anthropic/claude-3.7-sonnet': 'Anthropic',\n",
    "    'anthropic/claude-3.5-sonnet': 'Anthropic',\n",
    "    'deepseek/deepseek-chat-v3-0324': 'DeepSeek',\n",
    "    'google/gemma-2-9b-it': 'Google',\n",
    "    'deepseek/deepseek-r1': 'DeepSeek',\n",
    "    'anthropic/claude-3.5-haiku-20241022': 'Anthropic',\n",
    "    'openai/gpt-4o-mini': 'OpenAI',\n",
    "    'openai/gpt-4.5-preview': 'OpenAI',\n",
    "    'mistralai/mistral-small-3.1-24b-instruct-2503': 'Mistral',\n",
    "    'meta-llama/llama-3.1-8b-instruct': 'Meta-Llama',\n",
    "    'meta-llama/llama-3.1-70b-instruct': 'Meta-Llama',\n",
    "    'meta-llama/llama-3.1-405b-instruct': 'Meta-Llama',\n",
    "    'google/gemma-3-27b-it': 'Google',\n",
    "    'qwen/qwq-32b': 'Qwen',\n",
    "    'openai/chatgpt-4o-latest': 'OpenAI',\n",
    "    'cohere/command-a': 'Cohere',\n",
    "    'mistralai/mistral-nemo': 'Mistral',\n",
    "    'mistralai/mistral-small-24b-instruct-2501': 'Mistral',\n",
    "    'meta-llama/llama-3.2-3b-instruct': 'Meta-Llama',\n",
    "    'gemini-2.5-pro-exp-03-25': 'Google',  # 'gemini' => Google\n",
    "    'google/gemma-3-4b-it': 'Google',\n",
    "    'google/gemma-3-12b-it': 'Google',\n",
    "    'sam-paech/Darkest-muse-v1': 'Sam-Paech',\n",
    "    'ifable/gemma-2-Ifable-9B': 'Google',  # 'gemma' => Google\n",
    "    'ToastyPigeon/Gemma-3-Starshine-12B': 'Google',  # 'Gemma' => Google\n",
    "    'allura-org/Gemma-3-Glitter-12B': 'Google',       # 'Gemma' => Google\n",
    "    'liquid/lfm-7b': 'Liquid',\n",
    "    'chatgpt-4o-latest': 'OpenAI',\n",
    "    'anthropic/claude-3-haiku': 'Anthropic',\n",
    "    'rekaai/reka-flash-3:free': 'Reka',\n",
    "    'meta-llama/llama-3.2-1b-instruct': 'Meta-Llama',\n",
    "    'google/gemma-3-4b-it:free': 'Google',\n",
    "}\n",
    "\n",
    "##############################################################################\n",
    "# Family colors to match the above\n",
    "##############################################################################\n",
    "family_colors = {\n",
    "    'Google':     '#8a5cf5',\n",
    "    'Anthropic':  '#ffc13b',\n",
    "    'DeepSeek':   '#1eb980',\n",
    "    'OpenAI':     '#ff5c8d',\n",
    "    'Mistral':    '#ff6e40',\n",
    "    'Meta-Llama': '#1e3d59',\n",
    "    'Qwen':       '#b2df8a',\n",
    "    'Cohere':     '#bebada',\n",
    "    'Sam-Paech':  '#f28e2c',\n",
    "    'Liquid':     '#767676',\n",
    "    'Reka':       '#fb8072',\n",
    "    # If not in dictionary, default to \"Other\"\n",
    "    'Other':      '#cccccc'\n",
    "}\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Converts a scipy.cluster.hierarchy.ClusterNode into an ETE3 tree.\n",
    "##############################################################################\n",
    "def scipy_cluster_to_ete(scipy_node, ete_parent, id_to_label):\n",
    "    \"\"\"Recursively convert a scipy.cluster.hierarchy.ClusterNode into an ETE3 Tree.\"\"\"\n",
    "    if scipy_node.is_leaf():\n",
    "        leaf_name = id_to_label[scipy_node.id]\n",
    "        ete_parent.name = leaf_name\n",
    "    else:\n",
    "        left_child = ete_parent.add_child()\n",
    "        scipy_cluster_to_ete(scipy_node.left, left_child, id_to_label)\n",
    "\n",
    "        right_child = ete_parent.add_child()\n",
    "        scipy_cluster_to_ete(scipy_node.right, right_child, id_to_label)\n",
    "\n",
    "def linkage_to_ete_tree(linkage_matrix, labels):\n",
    "    \"\"\"Convert SciPy linkage + labels => ETE3 Tree using to_tree.\"\"\"\n",
    "    root_node = to_tree(linkage_matrix, rd=False)\n",
    "    ete_root = Tree()\n",
    "    id_to_label = dict(enumerate(labels))\n",
    "    scipy_cluster_to_ete(root_node, ete_root, id_to_label)\n",
    "    return ete_root\n",
    "\n",
    "##############################################################################\n",
    "# Node layout function that highlights one \"focus\" model in a standout color.\n",
    "##############################################################################\n",
    "def layout_fn_with_highlight(node, focus_model_name, highlight_color=\"#FF0000\"):\n",
    "    \"\"\"\n",
    "    - If node is internal, just give it a standard style.\n",
    "    - If it's a leaf, we color and label it.\n",
    "      If the leaf's name == focus_model_name, highlight in bright color.\n",
    "      Otherwise, use the family's color from model_to_family/family_colors.\n",
    "    \"\"\"\n",
    "    if not node.is_leaf():\n",
    "        # Internal node style\n",
    "        style = NodeStyle()\n",
    "        style[\"size\"] = 0\n",
    "        style[\"hz_line_width\"] = 2\n",
    "        style[\"vt_line_width\"] = 2\n",
    "        node.set_style(style)\n",
    "        return\n",
    "\n",
    "    # Leaf node: figure out color and label\n",
    "    leaf_label = node.name\n",
    "    # Access your existing dicts directly (model_to_family, family_colors)\n",
    "    family = model_to_family.get(leaf_label, \"Other\")\n",
    "    circle_color = family_colors.get(family, \"#cccccc\")\n",
    "    \n",
    "    if leaf_label == focus_model_name:\n",
    "        # Highlight this leaf in a special color\n",
    "        circle_color = highlight_color\n",
    "        text_face = TextFace(leaf_label, fsize=10, fgcolor=highlight_color)\n",
    "    else:\n",
    "        text_face = TextFace(leaf_label, fsize=10, fgcolor=\"black\")\n",
    "\n",
    "    # Attach label face to the branch\n",
    "    faces.add_face_to_node(text_face, node, column=0, position=\"branch-right\")\n",
    "\n",
    "    # Circle style\n",
    "    style = NodeStyle()\n",
    "    style[\"size\"] = 8\n",
    "    style[\"fgcolor\"] = circle_color\n",
    "    style[\"shape\"] = \"circle\"\n",
    "    style[\"hz_line_width\"] = 2\n",
    "    style[\"vt_line_width\"] = 2\n",
    "    node.set_style(style)\n",
    "\n",
    "##############################################################################\n",
    "# Renders an ETE3 tree, highlighting one particular leaf (focus_model_name).\n",
    "##############################################################################\n",
    "def render_ete_tree_focus(ete_tree, focus_model_name, output_image, layout=\"c\"):\n",
    "    \"\"\"\n",
    "    layout=\"c\" => circular phylo, layout=\"r\" => rectangular phylo.\n",
    "    Saves to output_image, highlighting the focus_model_name node.\n",
    "    \"\"\"\n",
    "    ts = TreeStyle()\n",
    "    ts.mode = layout\n",
    "    ts.show_leaf_name = False\n",
    "    ts.show_branch_length = False\n",
    "    ts.show_scale = False\n",
    "    if layout == 'r':\n",
    "        ts.branch_vertical_margin = 10\n",
    "\n",
    "    # Wrap our highlight function\n",
    "    def custom_layout(node):\n",
    "        layout_fn_with_highlight(node, focus_model_name)\n",
    "\n",
    "    ts.layout_fn = custom_layout\n",
    "\n",
    "    ete_tree.render(output_image, w=800, units=\"px\", tree_style=ts)\n",
    "    print(f\"Saved {layout.upper()} tree with highlight on '{focus_model_name}' => {output_image}\")\n",
    "\n",
    "##############################################################################\n",
    "# Builds a single 'combined' cluster from all models, then for each model,\n",
    "# saves a circular and rectangular dendrogram highlighting that model's leaf.\n",
    "#\n",
    "# Depends on the following existing items in your namespace:\n",
    "#   - elo_results_with_metrics.json  (the aggregated metrics file)\n",
    "#   - model_to_family, family_colors\n",
    "#   - get_updated_model_name(), sanitize_model_name()\n",
    "##############################################################################\n",
    "def build_combined_phylo_charts_for_all_models(\n",
    "    elo_file=\"elo_results_with_metrics.json\",\n",
    "    top_n=1500,\n",
    "    output_dir=\"results/charts\"\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Load all models' 'combined' top words/bigrams/trigrams from `elo_file`\n",
    "    2) Build presence/absence => cluster => single ETE Tree\n",
    "    3) For each model:\n",
    "       - highlight that leaf\n",
    "       - render circular + rectangular\n",
    "       - save to results/charts/[substituted_name]__phylo_tree_combined_*.png\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load the aggregated ELO data with metrics\n",
    "    with open(elo_file, 'r', encoding='utf-8') as f:\n",
    "        elo_data = json.load(f)\n",
    "\n",
    "    # Gather \"combined\" features for each model\n",
    "    # (top words + bigrams + trigrams)\n",
    "    model_to_feats = {}\n",
    "    for raw_model_name, info in elo_data.items():\n",
    "        w_count = top_n // 3\n",
    "        b_count = top_n // 3\n",
    "        t_count = top_n // 3\n",
    "\n",
    "        words = info.get(\"top_repetitive_words\", [])\n",
    "        bigrams = info.get(\"top_multi_prompt_bigrams\", [])\n",
    "        trigrams = info.get(\"top_multi_prompt_trigrams\", [])\n",
    "\n",
    "        # Sort & slice each type\n",
    "        top_words = []\n",
    "        if words:\n",
    "            sorted_w = sorted(words, key=lambda x: x.get('score', 0), reverse=True)[:w_count]\n",
    "            top_words = [x[\"word\"] for x in sorted_w]\n",
    "\n",
    "        top_bigrams = []\n",
    "        if bigrams:\n",
    "            sorted_b = sorted(bigrams, key=lambda x: x.get('frequency', 0), reverse=True)[:b_count]\n",
    "            top_bigrams = [x[\"ngram\"] for x in sorted_b]\n",
    "\n",
    "        top_trigrams = []\n",
    "        if trigrams:\n",
    "            sorted_t = sorted(trigrams, key=lambda x: x.get('frequency', 0), reverse=True)[:t_count]\n",
    "            top_trigrams = [x[\"ngram\"] for x in sorted_t]\n",
    "\n",
    "        combined_feats = set(top_words + top_bigrams + top_trigrams)\n",
    "        if combined_feats:\n",
    "            model_to_feats[raw_model_name] = combined_feats\n",
    "\n",
    "    if len(model_to_feats) < 2:\n",
    "        print(f\"Not enough models with combined features to build a tree. Found {len(model_to_feats)}.\")\n",
    "        return\n",
    "\n",
    "    # Build presence/absence DataFrame\n",
    "    all_models = sorted(model_to_feats.keys())\n",
    "    global_vocab = set()\n",
    "    for feats in model_to_feats.values():\n",
    "        global_vocab.update(feats)\n",
    "    global_vocab = sorted(global_vocab)\n",
    "\n",
    "    df = pd.DataFrame(0, index=all_models, columns=global_vocab, dtype=int)\n",
    "    for m in all_models:\n",
    "        for ft in model_to_feats[m]:\n",
    "            if ft in df.columns:\n",
    "                df.loc[m, ft] = 1\n",
    "\n",
    "    # If only 1 or 0 rows, skip\n",
    "    if len(df) < 2:\n",
    "        print(\"Only 1 or 0 models have valid combined features. Cannot cluster.\")\n",
    "        return\n",
    "\n",
    "    # Cluster via Jaccard + complete linkage\n",
    "    dist_mat = pdist(df.values, metric='jaccard')\n",
    "    linked = linkage(dist_mat, method='complete')\n",
    "    ete_tree = linkage_to_ete_tree(linked, df.index.tolist())\n",
    "\n",
    "    # For each model => highlight => circular + rectangular\n",
    "    for raw_model_name in all_models:\n",
    "        # Convert raw name if needed\n",
    "        updated_name = get_updated_model_name(raw_model_name)\n",
    "        out_base = sanitize_model_name(updated_name)\n",
    "\n",
    "        # Circular\n",
    "        circ_png = os.path.join(output_dir, f\"{out_base}__phylo_tree_combined_circular.png\")\n",
    "        render_ete_tree_focus(ete_tree, raw_model_name, circ_png, layout=\"c\")\n",
    "\n",
    "        # Rectangular\n",
    "        rect_png = os.path.join(output_dir, f\"{out_base}__phylo_tree_combined_rectangular.png\")\n",
    "        render_ete_tree_focus(ete_tree, raw_model_name, rect_png, layout=\"r\")\n",
    "\n",
    "    print(f\"\\nDone. Generated circular & rectangular phylo trees for {len(all_models)} models in '{output_dir}'.\")\n",
    "\n",
    "\n",
    "\n",
    "build_combined_phylo_charts_for_all_models(\n",
    "    elo_file=\"elo_results_with_metrics.json\",\n",
    "    top_n=1500,\n",
    "    output_dir=\"results/charts\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
